{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tahoe Regional Transportation Plan Forecasting\n",
    "> Data Engineering Tasks\n",
    "* Residential development forecasting for 2035 and 2050"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import os\n",
    "import arcpy\n",
    "from utils import *\n",
    "import numpy as np\n",
    "import pickle\n",
    "# external connection packages\n",
    "from sqlalchemy.engine import URL\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# pandas options\n",
    "pd.options.mode.copy_on_write = True\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.options.display.max_columns = 999\n",
    "pd.options.display.max_rows    = 999\n",
    "\n",
    "# my workspace \n",
    "workspace = r\"C:\\Users\\mbindl\\Desktop\\Workspace.gdb\"\n",
    "# current working directory\n",
    "local_path = pathlib.Path().absolute()\n",
    "\n",
    "# get bonus_condit\n",
    "# set data path as a subfolder of the current working directory TravelDemandModel\\2022\\\n",
    "data_dir = local_path.parents[0] / 'data'\n",
    "# folder to save processed data\n",
    "out_dir  = local_path.parents[0] / 'data/processed_data'\n",
    "# workspace gdb for stuff that doesnt work in memory\n",
    "# gdb = os.path.join(local_path,'Workspace.gdb')\n",
    "gdb = workspace\n",
    "# set environement workspace to in memory \n",
    "arcpy.env.workspace = 'memory'\n",
    "# # clear memory workspace\n",
    "# arcpy.management.Delete('memory')\n",
    "\n",
    "# overwrite true\n",
    "arcpy.env.overwriteOutput = True\n",
    "# Set spatial reference to NAD 1983 UTM Zone 10N\n",
    "sr = arcpy.SpatialReference(26910)\n",
    "\n",
    "# get parcels from the database\n",
    "# network path to connection files\n",
    "filePath = \"F:/GIS/PARCELUPDATE/Workspace/\"\n",
    "# database file path \n",
    "sdeBase    = os.path.join(filePath, \"Vector.sde\")\n",
    "sdeCollect = os.path.join(filePath, \"Collection.sde\")\n",
    "sdeTabular = os.path.join(filePath, \"Tabular.sde\")\n",
    "sdeEdit    = os.path.join(filePath, \"Edit.sde\")\n",
    "\n",
    "# Pickle variables\n",
    "# part 1 - spatial joins and new categorical fields\n",
    "parcel_pickle_part1    = data_dir / 'parcel_pickle1.pkl'\n",
    "# part 2 - forecasting applied\n",
    "parcel_pickle_part2    = data_dir / 'parcel_pickle2.pkl'\n",
    "\n",
    "# columsn to list\n",
    "initial_columns = [ 'APN',\n",
    "                    'APO_ADDRESS',\n",
    "                    'Residential_Units',\n",
    "                    'TouristAccommodation_Units',\n",
    "                    'CommercialFloorArea_SqFt',\n",
    "                    'YEAR',\n",
    "                    'JURISDICTION',\n",
    "                    'COUNTY',\n",
    "                    'OWNERSHIP_TYPE',\n",
    "                    'COUNTY_LANDUSE_DESCRIPTION',\n",
    "                    'EXISTING_LANDUSE',\n",
    "                    'REGIONAL_LANDUSE',\n",
    "                    'YEAR_BUILT',\n",
    "                    'PLAN_ID',\n",
    "                    'PLAN_NAME',\n",
    "                    'ZONING_ID',\n",
    "                    'ZONING_DESCRIPTION',\n",
    "                    'TOWN_CENTER',\n",
    "                    'LOCATION_TO_TOWNCENTER',\n",
    "                    'TAZ',\n",
    "                    'PARCEL_ACRES',\n",
    "                    'PARCEL_SQFT',\n",
    "                    'WITHIN_BONUSUNIT_BNDY',\n",
    "                    'WITHIN_TRPA_BNDY',\n",
    "                    'SHAPE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get SQL connection\n",
    "def get_conn(db):\n",
    "    # Get database user and password from environment variables on machine running script\n",
    "    db_user             = os.environ.get('DB_USER')\n",
    "    db_password         = os.environ.get('DB_PASSWORD')\n",
    "    # driver is the ODBC driver for SQL Server\n",
    "    driver              = 'ODBC Driver 17 for SQL Server'\n",
    "    # server names are\n",
    "    sql_12              = 'sql12'\n",
    "    sql_14              = 'sql14'\n",
    "    # make it case insensitive\n",
    "    db = db.lower()\n",
    "    # make sql database connection with pyodbc\n",
    "    if db   == 'sde_tabular':\n",
    "        connection_string = f\"DRIVER={driver};SERVER={sql_12};DATABASE={db};UID={db_user};PWD={db_password}\"\n",
    "        connection_url = URL.create(\"mssql+pyodbc\", query={\"odbc_connect\": connection_string})\n",
    "        engine = create_engine(connection_url)\n",
    "    elif db == 'tahoebmpsde':\n",
    "        connection_string = f\"DRIVER={driver};SERVER={sql_14};DATABASE={db};UID={db_user};PWD={db_password}\"\n",
    "        connection_url = URL.create(\"mssql+pyodbc\", query={\"odbc_connect\": connection_string})\n",
    "        engine = create_engine(connection_url)\n",
    "    elif db == 'sde':\n",
    "        connection_string = f\"DRIVER={driver};SERVER={sql_12};DATABASE={db};UID={db_user};PWD={db_password}\"\n",
    "        connection_url = URL.create(\"mssql+pyodbc\", query={\"odbc_connect\": connection_string})\n",
    "        engine = create_engine(connection_url)\n",
    "    # else return None\n",
    "    else:\n",
    "        engine = None\n",
    "    # connection file to use in pd.read_sql\n",
    "    return engine\n",
    "\n",
    "# save to pickle\n",
    "def to_pickle(data, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "    print(f'{filename} pickled')\n",
    "\n",
    "# save to pickle and feature class\n",
    "def to_pickle_fc(data, filename):\n",
    "    data.spatial.to_featureclass(filename)\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "    print(f'{filename} pickled and saved as feature class')\n",
    "\n",
    "# get a pickled file as a dataframe\n",
    "def from_pickle(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    print(f'{filename} unpickled')\n",
    "    return data\n",
    "def get_commercial_zones(df):\n",
    "    columns_to_keep = ['Zoning_ID', 'Category', 'Density']\n",
    "    # filter Use_Type to Multiple Family Dwelling\n",
    "    df = df.loc[df['Category'] == 'Commercial']\n",
    "    return df[columns_to_keep]\n",
    "\n",
    "def get_tourist_zones(df):\n",
    "    columns_to_keep = ['Zoning_ID', 'Category', 'Density']\n",
    "    # filter Use_Type to Multiple Family Dwelling\n",
    "    df = df.loc[df['Category'] == 'Tourist Accommodation']\n",
    "    return df[columns_to_keep]\n",
    "\n",
    "# function to get where Zoningin_ID Use_Type = Multi-Family and Density\n",
    "def get_mf_zones(df):\n",
    "    columns_to_keep = ['Zoning_ID', 'Use_Type', 'Density']\n",
    "    # filter Use_Type to Multiple Family Dwelling\n",
    "    df = df.loc[df['Use_Type'] == 'Multiple Family Dwelling']\n",
    "    return df[columns_to_keep]\n",
    "\n",
    "# function to get where Zoningin_ID Use_Type = Multi-Family and Density\n",
    "def get_sf_zones(df):\n",
    "    columns_to_keep = ['Zoning_ID', 'Use_Type', 'Density']\n",
    "    # filter Use_Type to Multiple Family Dwelling\n",
    "    df = df.loc[df['Use_Type'] == 'Single Family Dwelling']\n",
    "    return df[columns_to_keep]\n",
    "\n",
    "def get_mf_only_zones(df):\n",
    "    columns_to_keep = ['Zoning_ID', 'Use_Type', 'Density']\n",
    "    # filter Use_Type to Single Family Dwelling and not Multiple Family Dwelling\n",
    "    dfMF = get_mf_zones(df)\n",
    "    dfSF = get_sf_zones(df)\n",
    "    # get Zoning_ID that are in both dataframes\n",
    "    df = dfMF.loc[~dfMF['Zoning_ID'].isin(dfSF['Zoning_ID'])]\n",
    "    return df[columns_to_keep]\n",
    "\n",
    "def get_sf_only_zones(df):\n",
    "    columns_to_keep = ['Zoning_ID', 'Use_Type', 'Density']\n",
    "    # filter Use_Type to Single Family Dwelling and not Multiple Family Dwelling\n",
    "    dfMF = get_mf_zones(df)\n",
    "    dfSF = get_sf_zones(df)\n",
    "    df = dfSF.loc[~dfSF['Zoning_ID'].isin(dfMF['Zoning_ID'])]\n",
    "    return df[columns_to_keep]\n",
    "\n",
    "def get_sf_mf_zones(df):\n",
    "    columns_to_keep = ['Zoning_ID', 'Use_Type', 'Density']\n",
    "    # get SF and MF zones\n",
    "    dfSF = get_sf_zones(df)\n",
    "    dfMF = get_mf_zones(df)\n",
    "    # add the two dataframes together\n",
    "    df = pd.concat([dfSF, dfMF])\n",
    "    # only keep duplicate Zoning_ID\n",
    "    df = df[df.duplicated(subset=['Zoning_ID'], keep=False)]\n",
    "    return df[columns_to_keep]\n",
    "\n",
    "def get_recieving_zones(df):\n",
    "    columns_to_keep = ['Zoning_ID', 'SPECIAL_DESIGNATION']\n",
    "    # filter transfer recieving\n",
    "    df = df.loc[df['SPECIAL_DESIGNATION'] == 'Receive']\n",
    "    return df[columns_to_keep]\n",
    "\n",
    "def get_sending_zones(df):\n",
    "    columns_to_keep = ['Zoning_ID', 'SPECIAL_DESIGNATION']\n",
    "    df = df.loc[df['SPECIAL_DESIGNATION'] == 'Transfer']\n",
    "    return df[columns_to_keep]\n",
    "\n",
    "# function to forecast units on vacant parcels\n",
    "def forecast_residential_units(df, condition, target_sum, reason):\n",
    "    # filter to parcels available for development\n",
    "    sdfAvailable = df.loc[eval(condition)]\n",
    "    running_sum = 0\n",
    "    rows_to_fill = []\n",
    "    # Loop through the rows and fill the 'new_column'\n",
    "    for idx, row in sdfAvailable.iterrows():\n",
    "        # Calculate the remaining amount that can be filled\n",
    "        remaining_amount = target_sum - running_sum\n",
    "        if row['MAX_UNITS'] <= remaining_amount:\n",
    "            # If the current row's value fits, add it to the column\n",
    "            df.loc[idx, 'FORECASTED_RESIDENTIAL_UNITS'] = row['MAX_UNITS']\n",
    "            running_sum += row['MAX_UNITS']\n",
    "            if row['MAX_UNITS'] > 0:\n",
    "                rows_to_fill.append(idx)\n",
    "            if row['MAX_UNITS'] == remaining_amount:\n",
    "                break\n",
    "        elif remaining_amount > 0:\n",
    "            # If it exceeds the remaining amount, fill with the remaining value\n",
    "            df.loc[idx, 'FORECASTED_RESIDENTIAL_UNITS'] = remaining_amount\n",
    "            running_sum += remaining_amount\n",
    "            if row['MAX_UNITS'] > 0:\n",
    "                rows_to_fill.append(idx)\n",
    "            break\n",
    "        else:\n",
    "            continue\n",
    "    # reason for development\n",
    "    df.loc[rows_to_fill, 'FORECAST_REASON'] = reason\n",
    "    df_summary = pd.DataFrame({'Reason': [reason], 'Parcels_Available':[len(sdfAvailable)], 'Parcels_Used':[len(rows_to_fill)],\n",
    "                                'Total_Forecasted_Units': [running_sum], 'Total_Remaining_Units': [target_sum - running_sum]})   \n",
    "    return df, df_summary  \n",
    "\n",
    "# build a function to forecast residential units for infill parcels\n",
    "def forecast_residential_units_infill(df, condition, target_sum, reason):\n",
    "    # filter to parcels available for development\n",
    "    sdfAvailable = df.loc[eval(condition)]\n",
    "    running_sum = 0\n",
    "    rows_to_fill = []\n",
    "    # Loop through the rows and fill the 'new_column'\n",
    "    for idx, row in sdfAvailable.iterrows():\n",
    "        # Calculate the remaining amount that can be filled\n",
    "        remaining_amount = target_sum - running_sum\n",
    "        if row['POTENTIAL_UNITS'] <= remaining_amount:\n",
    "            # If the current row's value fits, add it to the column\n",
    "            df.loc[idx, 'FORECASTED_RESIDENTIAL_UNITS'] = row['POTENTIAL_UNITS']\n",
    "            running_sum += row['POTENTIAL_UNITS']\n",
    "            if row['POTENTIAL_UNITS'] > 0:\n",
    "                rows_to_fill.append(idx)\n",
    "            if row['POTENTIAL_UNITS'] == remaining_amount:\n",
    "                break\n",
    "        elif remaining_amount > 0:\n",
    "            # If it exceeds the remaining amount, fill with the remaining value\n",
    "            df.loc[idx, 'FORECASTED_RESIDENTIAL_UNITS'] = remaining_amount\n",
    "            running_sum += remaining_amount\n",
    "            if row['POTENTIAL_UNITS'] > 0:\n",
    "                rows_to_fill.append(idx)\n",
    "            break\n",
    "        else:\n",
    "            continue\n",
    "    # reason for development\n",
    "    df.loc[rows_to_fill, 'FORECAST_REASON'] = reason\n",
    "    df_summary = pd.DataFrame({'Reason': [reason], 'Parcels_Available':[len(sdfAvailable)], 'Parcels_Used':[len(rows_to_fill)],\n",
    "                                'Total_Forecasted_Units': [running_sum], 'Total_Remaining_Units': [target_sum - running_sum]})   \n",
    "    return df, df_summary\n",
    "\n",
    "# function to get the target sum\n",
    "def get_target_sum(df, Jurisdiction, Unit_Pool, zoning_type):\n",
    "    if zoning_type == 'MF':\n",
    "        return df.loc[(df['Jurisdiction'] == Jurisdiction) & (df['Unit_Pool'] == Unit_Pool), 'Future_Units_Adjusted_MF'].values[0]\n",
    "    elif zoning_type == 'SF':\n",
    "        return df.loc[(df['Jurisdiction'] == Jurisdiction) & (df['Unit_Pool'] == Unit_Pool), 'Future_Units_Adjusted_SF'].values[0]\n",
    "    elif zoning_type == 'Infill':\n",
    "        return df.loc[(df['Jurisdiction'] == Jurisdiction) & (df['Unit_Pool'] == Unit_Pool), 'Future_Units_Adjusted_Infill'].values[0]\n",
    "    return df.loc[(df['Jurisdiction'] == Jurisdiction) & (df['Unit_Pool'] == Unit_Pool), 'Future_Units_Adjusted'].values[0]\n",
    "\n",
    "# function to check parcels meeting criteria\n",
    "def check_parcel_condition(df, condition):\n",
    "    sdfAvailable = df.loc[eval(condition)]\n",
    "    # summarize parcel count, total potential units, and total existing units\n",
    "    df_summary = pd.DataFrame({'Parcels_Available':[len(sdfAvailable)], \n",
    "                               'Total_Max_Units':[sdfAvailable['MAX_UNITS'].sum()],\n",
    "                               'Total_Potential_Units':[sdfAvailable['POTENTIAL_UNITS'].sum()],\n",
    "                               'Total_Existing_Units':[sdfAvailable['Residential_Units'].sum(),]}\n",
    "                               )\n",
    "    return df_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in travel demand model base year parcel data\n",
    "parcel_base_tdm  = \"TravelDemandModel\\\\2022\\\\data\\\\raw_data\\\\parcel_pickle4.pkl\"\n",
    "parcel_base_path = local_path.parents[2].joinpath(parcel_base_tdm)\n",
    "# read in base year parcel data\n",
    "sdf_parcel_base  = pd.read_pickle(parcel_base_path)\n",
    "\n",
    "# parcel development layer polygons\n",
    "parcel_db = Path(sdeEdit) / \"SDE.Parcel\\\\SDE.Parcel_History_Attributed\"\n",
    "# query 2022 rows\n",
    "sdf_units = pd.DataFrame.spatial.from_featureclass(parcel_db)\n",
    "sdf_units = sdf_units.loc[sdf_units['YEAR'] == 2022]\n",
    "sdf_units.spatial.sr = sr\n",
    "\n",
    "# # get parcel level data from Collection SDE\n",
    "# vhr feature layer polygons \n",
    "vhr_db = Path(sdeCollect) / \"SDE.Parcel\\\\SDE.Parcel_VHR\"\n",
    "sdf_vhr = pd.DataFrame.spatial.from_featureclass(vhr_db)\n",
    "sdf_vhr.spatial.sr = sr\n",
    "# filter vhr layer to active status\n",
    "sdf_vhr = sdf_vhr.loc[sdf_vhr['Status'] == 'Active']\n",
    "\n",
    "# TAZ feature layer polygons\n",
    "taz_db = Path(sdeBase) / \"SDE.Transportation\\\\SDE.Transportation_Analysis_Zone\"\n",
    "# get as spatial dataframe\n",
    "sdf_taz = pd.DataFrame.spatial.from_featureclass(taz_db)\n",
    "# set spatial reference to NAD 1983 UTM Zone 10N\n",
    "sdf_taz.spatial.sr = sr\n",
    "\n",
    "# censuse feature class\n",
    "census_fc    = Path(sdeBase) / \"SDE.Census\\\\SDE.Tahoe_Census_Geography\"\n",
    "# bouns unit boundary feature class\n",
    "bonus_unit_fc = Path(sdeBase) / \"SDE.Planning\\SDE.Bonus_unit_boundary\"\n",
    "\n",
    "# disable Z values on block group feature layer\n",
    "with arcpy.EnvManager(outputZFlag=\"Disabled\"):    \n",
    "    arcpy.conversion.FeatureClassToGeodatabase(\n",
    "        Input_Features=\"F:\\GIS\\DB_CONNECT\\Vector.sde\\SDE.Census\\SDE.Tahoe_Census_Geography\",\n",
    "        Output_Geodatabase=r\"C:\\Users\\mbindl\\Desktop\\Workspace.gdb\"\n",
    "    )\n",
    "# disable Z values on block group feature layer\n",
    "with arcpy.EnvManager(outputZFlag=\"Disabled\"):    \n",
    "    arcpy.conversion.FeatureClassToGeodatabase(\n",
    "        Input_Features=\"F:\\GIS\\DB_CONNECT\\Vector.sde\\SDE.Planning\\SDE.Bonus_unit_boundary\",\n",
    "        Output_Geodatabase=r\"C:\\Users\\mbindl\\Desktop\\Workspace.gdb\"\n",
    "    )\n",
    "\n",
    "# block group feature layer polygons with no Z\n",
    "sdf_block = pd.DataFrame.spatial.from_featureclass(Path(gdb) / 'Tahoe_Census_Geography')\n",
    "sdf_block = sdf_block.loc[(sdf_block['YEAR'] == 2020) & (sdf_block['GEOGRAPHY'] == 'Block Group')]\n",
    "sdf_block.spatial.sr = sr\n",
    "\n",
    "# bonus unit boundary wihtout Z\n",
    "sdf_bonus = pd.DataFrame.spatial.from_featureclass(Path(gdb) / 'Bonus_unit_boundary')\n",
    "sdf_bonus.spatial.sr = sr\n",
    "\n",
    "# get parcel level data from LTinfo\n",
    "dfIPES       = pd.read_json(\"https://www.laketahoeinfo.org/WebServices/GetParcelIPESScores/JSON/e17aeb86-85e3-4260-83fd-a2b32501c476\")\n",
    "dfLCV_LTinfo = pd.read_json('https://www.laketahoeinfo.org/WebServices/GetParcelsByLandCapability/JSON/e17aeb86-85e3-4260-83fd-a2b32501c476')\n",
    "dfRetired    = pd.read_json(\"https://www.laketahoeinfo.org/WebServices/GetAllParcels/JSON/e17aeb86-85e3-4260-83fd-a2b32501c476\")\n",
    "dfBankedDev  = pd.read_json('https://www.laketahoeinfo.org/WebServices/GetBankedDevelopmentRights/JSON/e17aeb86-85e3-4260-83fd-a2b32501c476')\n",
    "dfTransacted = pd.read_json('https://www.laketahoeinfo.org/WebServices/GetTransactedAndBankedDevelopmentRights/JSON/e17aeb86-85e3-4260-83fd-a2b32501c476')\n",
    "dfAllParcels = pd.read_json('https://www.laketahoeinfo.org/WebServices/GetAllParcels/JSON/e17aeb86-85e3-4260-83fd-a2b32501c476')\n",
    "\n",
    "# get use tables \n",
    "# zoning data\n",
    "sde_engine = get_conn('sde')\n",
    "with sde_engine.begin() as conn:\n",
    "    df_uses    = pd.read_sql(\"SELECT * FROM sde.SDE.PermissibleUses\", conn)\n",
    "    df_special = pd.read_sql(\"SELECT * FROM sde.SDE.Special_Designation\", conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parcel Data Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spatial join to get TAZ\n",
    "arcpy.SpatialJoin_analysis(sdf_units, sdf_taz, \"Existing_Development_TAZ\", \n",
    "                           \"JOIN_ONE_TO_ONE\", \"KEEP_ALL\", \"\", \"HAVE_THEIR_CENTER_IN\")\n",
    "# spatial join to get Block Group\n",
    "arcpy.SpatialJoin_analysis(sdf_units, sdf_block, \"Existing_Development_BlockGroup\", \n",
    "                           \"JOIN_ONE_TO_ONE\", \"KEEP_ALL\", \"\", \"HAVE_THEIR_CENTER_IN\")\n",
    "# spatial join of Bonus Unit Boundary\n",
    "arcpy.SpatialJoin_analysis(sdf_units, sdf_bonus, \"Existing_Development_BonusUnitBoundary\",\n",
    "                            \"JOIN_ONE_TO_ONE\", \"KEEP_ALL\", \"\", \"INTERSECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spatial dataframe with only initial columns\n",
    "sdfParcels = sdf_units[initial_columns]\n",
    "\n",
    "# get results of spatial joins as spatial dataframes\n",
    "sdf_units_taz   = pd.DataFrame.spatial.from_featureclass(\"Existing_Development_TAZ\", sr=sr)  \n",
    "sdf_units_block = pd.DataFrame.spatial.from_featureclass(\"Existing_Development_BlockGroup\", sr=sr)\n",
    "sdf_units_bonus = pd.DataFrame.spatial.from_featureclass(\"Existing_Development_BonusUnitBoundary\", sr=sr)\n",
    "# cast to string\n",
    "sdf_units_bonus['WITHIN_BONUSUNIT_BNDY'] = sdf_units_bonus['WITHIN_BONUSUNIT_BNDY'].astype(str)\n",
    "sdf_units_bonus['WITHIN_BONUSUNIT_BNDY'] = 'No'\n",
    "# if Id is not NA then within bonus unit boundary = yes, else\n",
    "sdf_units_bonus.loc[sdf_units_bonus['Id'].notna(), 'WITHIN_BONUSUNIT_BNDY'] = 'Yes'\n",
    "\n",
    "# map dictionary to sdf_units dataframe to fill in TAZ and Block Group fields\n",
    "sdfParcels['TAZ']                   = sdfParcels.APN.map(dict(zip(sdf_units_taz.APN,   sdf_units_taz.TAZ_1)))\n",
    "sdfParcels['BLOCK_GROUP']           = sdfParcels.APN.map(dict(zip(sdf_units_block.APN, sdf_units_block.TRPAID)))\n",
    "# map IPES score to parcels\n",
    "sdfParcels['IPES_SCORE']            = sdfParcels['APN'].map(dict(zip(dfIPES.APN, dfIPES.IPESScore)))\n",
    "sdfParcels['IPES_SCORE_TYPE']       = sdfParcels['APN'].map(dict(zip(dfIPES.APN, dfIPES.IPESScoreType)))\n",
    "# retired parcels\n",
    "sdfParcels['RETIRED']               = sdfParcels['APN'].map(dict(zip(dfAllParcels.APN, dfAllParcels.RetiredFromDevelopment)))\n",
    "sdfParcels['WITHIN_BONUSUNIT_BNDY'] = sdfParcels['APN'].map(dict(zip(sdf_units_bonus.APN, sdf_units_bonus.WITHIN_BONUSUNIT_BNDY)))\n",
    "# define housnig zoning and density\n",
    "sdfParcels['HOUSING_ZONING']          = 'NA'\n",
    "sdfParcels['COMMERCIAL_ALLOWED']      = 'No'\n",
    "sdfParcels['TOURIST_ALLOWED']         = 'No'\n",
    "\n",
    "# if the zoning id is in the list of multiple family zones then set to MF\n",
    "sdfParcels.loc[sdfParcels['ZONING_ID'].isin(get_sf_mf_zones(df_uses)['Zoning_ID']), 'HOUSING_ZONING'] = 'SF/MF'\n",
    "# if the zoning id is in the list of single family zones and not in the multiple family zones then set to SF only\n",
    "sdfParcels.loc[sdfParcels['ZONING_ID'].isin(get_sf_only_zones(df_uses)['Zoning_ID']), 'HOUSING_ZONING'] = 'SF_only'\n",
    "# if the zoning id is in the list of multiple family zones and not in the single family zones then set to MF only\n",
    "sdfParcels.loc[sdfParcels['ZONING_ID'].isin(get_mf_only_zones(df_uses)['Zoning_ID']), 'HOUSING_ZONING'] = 'MF_only'\n",
    "# if the zoning id is in the list of commercial zones then set to Commercial\n",
    "sdfParcels.loc[sdfParcels['ZONING_ID'].isin(get_commercial_zones(df_uses)['Zoning_ID']), 'COMMERCIAL_ALLOWED'] = 'Yes'\n",
    "# if the zoning id is in the list of tourist zones then set to Tourist Accommodation\n",
    "sdfParcels.loc[sdfParcels['ZONING_ID'].isin(get_tourist_zones(df_uses)['Zoning_ID']), 'TOURIST_ALLOWED'] = 'Yes'\n",
    "\n",
    "# if COUNTY is in EL or PL and SF allowed then set ADU_ALLOWED to yes or if COUNTY is in WA, DG, or CC and parcel acres is greater than 1 and SF allowed then set ADU_ALLOWED to yes\n",
    "sdfParcels['ADU_ALLOWED'] = 'No'\n",
    "sdfParcels.loc[(sdfParcels['COUNTY'].isin(['EL','PL'])) & (~sdfParcels['HOUSING_ZONING'].isin(['MF_only', 'NA'])), 'ADU_ALLOWED'] = 'Yes'\n",
    "sdfParcels.loc[(sdfParcels['COUNTY'].isin(['WA','DG','CC'])) & (sdfParcels['PARCEL_ACRES']>=1) &(~sdfParcels['HOUSING_ZONING'].isin(['MF_only', 'NA'])), 'ADU_ALLOWED'] = 'Yes'\n",
    "\n",
    "# get density for MF and MF only zones, max residential units, and adjusted residential units\n",
    "dfMF = get_mf_zones(df_uses)\n",
    "sdfParcels['DENSITY']                    = sdfParcels['ZONING_ID'].map(dict(zip(dfMF.Zoning_ID, dfMF.Density)))\n",
    "sdfParcels['MAX_RESIDENTIAL_UNITS']      = sdfParcels['PARCEL_ACRES'] * sdfParcels['DENSITY']\n",
    "sdfParcels['MAX_UNITS']                  = sdfParcels['MAX_RESIDENTIAL_UNITS']*0.6\n",
    "sdfParcels['MAX_UNITS']                  = sdfParcels['MAX_UNITS'].fillna(0).astype(int)\n",
    "\n",
    "# set SF only zones to 1 max unit\n",
    "sdfParcels.loc[sdfParcels['HOUSING_ZONING'] == 'SF_only', 'MAX_UNITS'] = 1\n",
    "\n",
    "# set field for underbuilt evaluation\n",
    "sdfParcels['POTENTIAL_UNITS'] = 0\n",
    "sdfParcels['POTENTIAL_UNITS'] = sdfParcels['MAX_UNITS'] - sdfParcels['Residential_Units']\n",
    "# set negative values to 0\n",
    "sdfParcels.loc[sdfParcels['POTENTIAL_UNITS'] < 0, 'POTENTIAL_UNITS'] = 0\n",
    "\n",
    "# calculate parcels with the greatest buildable potential  filter to the top 10% of parcels\n",
    "# what value is in the top 10% of the potential buildable units\n",
    "top_10_threshold = sdfParcels.POTENTIAL_UNITS.quantile(0.9)\n",
    "# filter out rows where POTENTIAL_BUILDABLE_UNITS is NaN\n",
    "sdfParcels['TOP_TEN_POTENTIAL_UNITS'] = sdfParcels.apply(lambda x: 'Yes' if x['POTENTIAL_UNITS'] >= top_10_threshold else 'No', axis=1)\n",
    "\n",
    "# set FORECASTED_RESIDENTIAL_UNITS to 0\n",
    "sdfParcels['FORECASTED_RESIDENTIAL_UNITS']     = 0\n",
    "# set FORECAST_COMMERCIAN_UNITS to 0\n",
    "sdfParcels['FORECASTED_COMMERCIAL_SQFT']       = 0\n",
    "# set FORECAST_TOURIST_UNITS to 0\n",
    "sdfParcels['FORECASTED_TOURIST_UNITS']         = 0\n",
    "# set FORECAST_REASON to na\n",
    "sdfParcels['FORECAST_REASON']                  = None\n",
    "# FORECASTED_OCCUPANCY_RATE as a float field\n",
    "sdfParcels['FORECASTED_RES_OCCUPANCY_RATE']    = 0.0\n",
    "\n",
    "# export to pickle\n",
    "sdfParcels.to_pickle(parcel_pickle_part1)\n",
    "# to feature class\n",
    "sdfParcels.spatial.to_featureclass(Path(gdb)/'Parcel_Base_2022')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Year Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residential Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Assign Known Projects\n",
    "* Assign using Lookup_Lists\\forecast_residential_assigned_units.csv: \n",
    "    * Known Residential Allocations from 2023-2024, \n",
    "    * Known Residential Bonus Units from permitted projects, \n",
    "    * applications in review, and \n",
    "    * RBU reservations in LT Info\n",
    "    * Known Accessory Dwelling permits not completed\n",
    "    * Remove Known Banking projects that removed units in 2023-2024\n",
    "* Calcuate Remaining local jurisdiction pool units less units used for known projects\n",
    "    \n",
    "2) Assign Residential Bonus Units within Bonus Unit Boundary\n",
    "* Full build out of CTC Asset Lands using jurisdiction bonus unit pools\n",
    "* Identify vacant buildable lots within Bonus Unit boundary\n",
    "* Assign remaining jurisdiction pool units to available parcels within jurisidiction\n",
    "\n",
    "3) Assigne remaining Jurisdiction Residential Bonus and General Units\n",
    "* Identify\tVacant buildable lots with allowed Multi-family use, calculate allowed density\n",
    "* Assign 15% of remaining local jurisdiction Residential Allocation pool units to available multi-family parcels within jurisidiction\n",
    "* Assign 35% of remaining Banked units to available multi-family parcels (use adjusted weighting from existing residential units?)\n",
    "* Assign 35% of remaining Converted units to available multi-family parcels (use adjusted weighting from existing residential units?)\n",
    "    \n",
    "4) Assign remaining TRPA pool units to available parcels throughout region (use adjusted weighting from existing residential units?)\n",
    "* Evaluate Vacant Buildable Lots with Single-family Residential Allowed Use\t\n",
    "* Identify\tVacant buildable lots with allowed Single-family use\n",
    "* Identify\tAccessory Dwelling Uses Allowed (All California Parcels and NV Parcels Greater than 1 Acre)\n",
    "* Evaluate Underbuilt parcels with Multi-family Residential Allowed Use\t\n",
    "* Identify\tUnderbuilt Residential lots with allowed Multi-family use\n",
    "* Evaluate Underbuilt parcels with Accessory Dwelling Uses Allowed (All California Parcels and NV Parcels Greater than 1 Acre)\t\n",
    "* Identify parcels that are in Town Centers or within a quarter mile and are top x% of underbuilt parcels. \n",
    "* Underbuilt = exclude existing condo and common area land uses. sf mf or mixed use\n",
    "* ADU potential = exclude existing condo or common area land uses, and wait to use any NV parcels>acre. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Get the Parcel Base Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get pickle 1 as a spatially enabled dataframe - spatial joins, foreign keys, and new categorical fields added already\n",
    "sdfParcels = from_pickle(parcel_pickle_part1)\n",
    "# Randomly sort parcels so that development can be assigned randomly\n",
    "sdfParcels = sdfParcels.sample(frac=1).reset_index(drop=True)\n",
    "# Export index and apn to a csv file for future reference with a name that includes the date and time\n",
    "# # This will allow us to recreate the same random order in the future\n",
    "sdfParcels[['APN']].to_csv(f\"Parcel_Sort_Order_{pd.Timestamp.now().strftime('%Y%m%d%H%M%S')}.csv\", index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Get Lookup Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to lookup lists\n",
    "res_assigned_lookup = \"Lookup_Lists/forecast_residential_assigned_units.csv\"\n",
    "res_zoned_lookup    = \"Lookup_Lists/forecast_residential_zoned_units.csv\"\n",
    "ctc_assetlands_lookup = \"Lookup_Lists/CTC_AssetLands_Lookup.csv\"\n",
    "\n",
    "# get zoned and assigned lookup lists as data frames\n",
    "dfResZoned    = pd.read_csv(res_zoned_lookup)\n",
    "dfResAssigned = pd.read_csv(res_assigned_lookup)\n",
    "# get lookup list for CTC asset lands (17 parcels)\n",
    "ctc_parcels = pd.read_csv(ctc_assetlands_lookup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Assign Known Projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast Known Residential Projects from 2023-2024\n",
    "# group dfResAssigned by APN and sum Unit Change to aggregate to one total for duplciate \n",
    "dfResAssignedGrouped_APN = dfResAssigned.groupby('APN').sum('Unit Change').reset_index()\n",
    "# assign forecast residential units for assigned projects\n",
    "sdfParcels['FORECASTED_RESIDENTIAL_UNITS'] = sdfParcels.APN.map(dict(zip(dfResAssignedGrouped_APN.APN, dfResAssignedGrouped_APN['Unit Change'])))\n",
    "# forecast reason = Assigned for APNs in dfResAssignedGrouped\n",
    "sdfParcels.loc[sdfParcels['APN'].isin(dfResAssigned['APN']), 'FORECAST_REASON'] = 'Assigned'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdfParcels.groupby(['JURISDICTION','FORECAST_REASON'])['FORECASTED_RESIDENTIAL_UNITS'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total forecasted units\n",
    "total_forecasted_units = sdfParcels['FORECASTED_RESIDENTIAL_UNITS'].sum()\n",
    "print(f'Total Forecasted Units: {total_forecasted_units}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Forecast full buildout of CTC Asset Lands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CTC Asset Lands ##\n",
    "# set the forecast reason to CTC Asset Lands for the 17 parcels n\n",
    "sdfParcels.loc[(sdfParcels['APN'].isin(ctc_parcels['APN'])) & (sdfParcels['FORECAST_REASON']!='Assigned'), 'FORECAST_REASON'] = 'CTC Asset Lands'\n",
    "# CTC asset lands that are truly buildable\n",
    "ctc_condition          = \"(sdfParcels['FORECAST_REASON'] == 'CTC Asset Lands') & (sdfParcels['MAX_UNITS'] > 0)\"\n",
    "# assign POTEINTIAL_UNITS to FORECASTED_RESIDENTIAL_UNITS for CTC Asset Lands that are buildable and not built by 2024\n",
    "sdfParcels.loc[eval(ctc_condition), 'FORECASTED_RESIDENTIAL_UNITS'] = sdfParcels['MAX_UNITS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdfParcels.groupby(['JURISDICTION','FORECAST_REASON'])['FORECASTED_RESIDENTIAL_UNITS'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Subtract Assigned Units from the appropriate pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subtract Assigned units from the appropriate pool\n",
    "# group dfResAssigned by Jurisdiction and Unit_Pool\n",
    "dfGroup_Assigned = dfResAssigned.groupby(['Jurisdiction', 'Unit_Pool']).sum('Unit Change').reset_index()\n",
    "# drop Occupancy_Rate and Year columns\n",
    "dfGroup_Assigned = dfGroup_Assigned.drop(columns=['Occupancy_Rate'])\n",
    "# rename Unit Change to Unit_Change\n",
    "dfGroup_Assigned = dfGroup_Assigned.rename(columns={'Unit Change':'Unit_Change'})\n",
    "\n",
    "# merge dfResAssignedGrouped with dfResZoned on Jurisdiction and Pool\n",
    "dfPool_Assigned = pd.merge(dfResZoned, dfGroup_Assigned, on=['Jurisdiction', 'Unit_Pool'], how='left')\n",
    "\n",
    "# fill NaN with 0\n",
    "dfPool_Assigned['Unit_Change'] = dfPool_Assigned['Unit_Change'].fillna(0)\n",
    "# subtract known project aggregations from the zoned unit pools\n",
    "dfPool_Assigned['Future_Units_Adjusted'] = dfPool_Assigned['Future_Units'] - dfPool_Assigned['Unit_Change']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Subtract the CTC asset lands buildout from the appropriate pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter to CTC Asset Lands parcels \n",
    "sdfCTC = sdfParcels.loc[sdfParcels['FORECAST_REASON'] == 'CTC Asset Lands']\n",
    "# sum of forecasted residential units where forecast reason = ctc asset lands\n",
    "sdfCTC_ForecastedByJurisdiction = sdfCTC.groupby('JURISDICTION')['FORECASTED_RESIDENTIAL_UNITS'].sum().reset_index()\n",
    "# set unit pool to Bonus Unit or General based on Jurisdiction\n",
    "sdfCTC_ForecastedByJurisdiction.loc[(sdfCTC_ForecastedByJurisdiction['JURISDICTION']=='CSLT'), 'Unit_Pool'] = 'Bonus Unit'\n",
    "sdfCTC_ForecastedByJurisdiction.loc[(sdfCTC_ForecastedByJurisdiction['JURISDICTION']=='CSLT'), 'JURISDICTION']   = 'TRPA'\n",
    "\n",
    "sdfCTC_ForecastedByJurisdiction.loc[(sdfCTC_ForecastedByJurisdiction['JURISDICTION']=='PL'), 'Unit_Pool']   = 'Bonus Unit'\n",
    "\n",
    "sdfCTC_ForecastedByJurisdiction.loc[(sdfCTC_ForecastedByJurisdiction['JURISDICTION']=='EL'), 'Unit_Pool']   = 'Bonus Unit'\n",
    "sdfCTC_ForecastedByJurisdiction.loc[(sdfCTC_ForecastedByJurisdiction['JURISDICTION']=='EL'), 'JURISDICTION'] = 'TRPA'\n",
    "\n",
    "# mere rows with same Jurisdiction and Unit_Pool and sum forecasted residential units\n",
    "sdfCTC_ForecastedByJurisdiction = sdfCTC_ForecastedByJurisdiction.groupby(['JURISDICTION', 'Unit_Pool'])['FORECASTED_RESIDENTIAL_UNITS'].sum().reset_index()\n",
    "\n",
    "# rename columns\n",
    "sdfCTC_ForecastedByJurisdiction.rename(columns={'JURISDICTION': 'Jurisdiction', 'FORECASTED_RESIDENTIAL_UNITS': 'Forecasted_CTC'}, inplace=True)\n",
    "\n",
    "# Subtract CTC asset lands from the appropriate pool\n",
    "dfPool_CTC = sdfCTC_ForecastedByJurisdiction.copy()\n",
    "\n",
    "# merge with dfResMerge\n",
    "dfPool_CTC = pd.merge(dfPool_Assigned, dfPool_CTC, on=['Jurisdiction', 'Unit_Pool'], how='left')\n",
    "\n",
    "# fill NaN with 0\n",
    "dfPool_CTC['Forecasted_CTC'] = dfPool_CTC['Forecasted_CTC'].fillna(0)\n",
    "# subtract CTC asset lands from the appropriate pool\n",
    "dfPool_CTC['Future_Units_Adjusted'] = dfPool_CTC['Future_Units_Adjusted'] - dfPool_CTC['Forecasted_CTC']\n",
    "# add CTC Max Build to the unit change\n",
    "dfPool_CTC['Unit_Change'] = dfPool_CTC['Unit_Change'] + dfPool_CTC['Forecasted_CTC']\n",
    "# drop CTC Built column\n",
    "dfPool_CTC.drop(columns=['Forecasted_CTC'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Setup Unit Pools Proportion to be Used in Each Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPool = dfPool_CTC.copy()\n",
    "# proportion target of forecast development by type\n",
    "portion_multifamily = .35\n",
    "portion_singlefamily = .5\n",
    "portion_infill = .15\n",
    "# Set units to use for each zoning type\n",
    "dfPool['Future_Units_Adjusted'] = dfPool['Future_Units_Adjusted'].fillna(0)\n",
    "dfPool['Future_Units_Adjusted_MF'] = (dfPool['Future_Units_Adjusted'] * portion_multifamily).round().astype(int)\n",
    "dfPool['Future_Units_Adjusted_SF'] = (dfPool['Future_Units_Adjusted'] * portion_singlefamily).round().astype(int)\n",
    "dfPool['Future_Units_Adjusted_Infill'] = (dfPool['Future_Units_Adjusted'] * portion_infill).round().astype(int)\n",
    "# Assign any rounding error to the single family pool\n",
    "dfPool['Adjustment'] = dfPool['Future_Units_Adjusted'] - dfPool['Future_Units_Adjusted_MF'] - dfPool['Future_Units_Adjusted_SF'] - dfPool['Future_Units_Adjusted_Infill']\n",
    "dfPool['Future_Units_Adjusted_SF'] = dfPool['Future_Units_Adjusted_SF'] + dfPool['Adjustment']\n",
    "dfPool.drop(columns=['Adjustment'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Define Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##------------------------------------ Conditional Statements for Forecasting Residential Unit Development------------------------------ ##\n",
    "# vacant buildable criteria\n",
    "vacant_buildable_criteria        = \"(df['EXISTING_LANDUSE'] == 'Vacant') & (df['OWNERSHIP_TYPE'] == 'Private') & (df['RETIRED'] == 'No') & (df['IPES_SCORE'] > 0)\"\n",
    "placer_vacant_buildable_criteria = \"(df['EXISTING_LANDUSE'] == 'Vacant') & (df['OWNERSHIP_TYPE'] == 'Private') & (df['RETIRED'] == 'No') & (df['IPES_SCORE'] > 726)\" \n",
    "\n",
    "# Within TRPA Boundary as condition for all\n",
    "trpa_boundary_criteria = \"(df['WITHIN_TRPA_BNDY'] == 1)\"\n",
    "bonus_unit_criteria    = \"(df['WITHIN_BONUSUNIT_BNDY'] == 'Yes')\"\n",
    "no_zoning_criteria     = \"(df['HOUSING_ZONING'] != 'NA')\"\n",
    "sf_only_criteria       = \"(df['HOUSING_ZONING'] == 'SF_only')\"\n",
    "mf_only_criteria       = \"(df['HOUSING_ZONING'] == 'MF_only')\"\n",
    "sf_mf_criteria         = \"(df['HOUSING_ZONING'].isin(['SF/MF', 'MF_only']))\"\n",
    "adu_criteria           = \"(df['ADU_ALLOWED'] == 'Yes') & (df['Residential_Units']>0)\"\n",
    "towncenter_condition   = \"(~df['TOWN_CENTER'].isna())\"\n",
    "top_10_condition       = \"(df['TOP_TEN_POTENTIAL_UNITS'] == 'Yes')\"\n",
    "condo_size_condition   = \"(df['PARCEL_ACRES'] >= 0.15)&(~df['EXISTING_LANDUSE'].isin(['Condominium', 'Condomunium Common Area']))\"\n",
    "ready_to_forecast      = \"(df['FORECAST_REASON'].isna())&(df['OWNERSHIP_TYPE'] == 'Private')\"\n",
    "\n",
    "# setup f string to change jurisdiction in bonus condition\n",
    "bonus_vacant_condition_template  = (\"(df['JURISDICTION'] == '{}') & \"  + \n",
    "                                    bonus_unit_criteria + \" & \" + trpa_boundary_criteria + \" & \" + \n",
    "                                    vacant_buildable_criteria + \" & \" + sf_mf_criteria + \" & \" + \n",
    "                                    ready_to_forecast + \" & \" + condo_size_condition)\n",
    "vacant_condition_template        = (\"(df['JURISDICTION'] == '{}') & \"  + \n",
    "                                    trpa_boundary_criteria + \" & \" + \n",
    "                                    vacant_buildable_criteria + \" & \" + sf_mf_criteria + \" & \" + \n",
    "                                    ready_to_forecast + \" & \" + condo_size_condition)\n",
    "placer_vacant_condition_template = (\"(df['JURISDICTION'] == '{}') & \" + \n",
    "                                    trpa_boundary_criteria + \" & \" + placer_vacant_buildable_criteria + \" & \" + \n",
    "                                    sf_mf_criteria + \" & \" + \n",
    "                                    ready_to_forecast + \" & \" + condo_size_condition)\n",
    "infill_condition_template        = (\"(df['JURISDICTION'] == '{}') & \"  + \n",
    "                                    trpa_boundary_criteria + \" & \" + vacant_buildable_criteria + \" & \" + \n",
    "                                    sf_mf_criteria + \" & \" + \n",
    "                                    ready_to_forecast + \" & \" + top_10_condition)\n",
    "adu_condition_template           = (\"(df['JURISDICTION'] == '{}') & \"  + \n",
    "                                    trpa_boundary_criteria + \" & \" + adu_criteria + \" & \" + \n",
    "                                    ready_to_forecast)\n",
    "towncenter_condition_template    = (\"(df['JURISDICTION'] == '{}') & \"  + \n",
    "                                    trpa_boundary_criteria + \" & \" + towncenter_condition + \" & \" + \n",
    "                                    ready_to_forecast)\n",
    "\n",
    "# list of jurisdictions\n",
    "jurisdictions = ['CSLT', 'DG', 'PL', 'WA','TRPA']\n",
    "# loop through jurisdictions in bonus_condition\n",
    "for j in jurisdictions:\n",
    "    condition = bonus_vacant_condition_template.format(j)\n",
    "    print(condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##------------------------------------ Conditional Statements for Forecasting Residential Unit Development------------------------------ ##\n",
    "# vacant buildable criteria\n",
    "vacant_buildable_criteria        = \"(df['EXISTING_LANDUSE'] == 'Vacant') & (df['OWNERSHIP_TYPE'] == 'Private') & (df['RETIRED'] == 'No') & (df['IPES_SCORE'] > 0)\"\n",
    "placer_vacant_buildable_criteria = \"(df['EXISTING_LANDUSE'] == 'Vacant') & (df['OWNERSHIP_TYPE'] == 'Private') & (df['RETIRED'] == 'No') & (df['IPES_SCORE'] > 726)\" \n",
    "\n",
    "# Within TRPA Boundary as condition for all\n",
    "trpa_boundary_criteria = \"(df['WITHIN_TRPA_BNDY'] == 1)\"\n",
    "bonus_unit_criteria    = \"(df['WITHIN_BONUSUNIT_BNDY'] == 'Yes')\"\n",
    "no_zoning_criteria     = \"(df['HOUSING_ZONING'] != 'NA')\"\n",
    "sf_only_criteria       = \"(df['HOUSING_ZONING'] == 'SF_only')\"\n",
    "mf_only_criteria       = \"(df['HOUSING_ZONING'] == 'MF_only')\"\n",
    "sf_mf_criteria         = \"(df['HOUSING_ZONING'].isin(['SF/MF', 'MF_only']))\"\n",
    "adu_criteria           = \"(df['ADU_ALLOWED'] == 'Yes') & (df['Residential_Units']>0)\"\n",
    "towncenter_condition   = \"(~df['TOWN_CENTER'].isna())\"\n",
    "top_10_condition       = \"(df['TOP_TEN_POTENTIAL_UNITS'] == 'Yes')\"\n",
    "condo_size_condition   = \"(df['PARCEL_ACRES'] >= 0.15)&(~df['EXISTING_LANDUSE'].isin(['Condominium', 'Condomunium Common Area']))\"\n",
    "ready_to_forecast      = \"(df['FORECAST_REASON'].isna())&(df['OWNERSHIP_TYPE'] == 'Private')\"\n",
    "\n",
    "##------------------------------------------------- Jurisdiction Specific Conditions ---------------------------------------------------- ##\n",
    "\n",
    "# jurisdiction bonus unit conditions\n",
    "CSLT_Bonus_SF_condition       = \"(df['JURISDICTION'] == 'CSLT')\" + \" & \" + bonus_unit_criteria + \" & \" + trpa_boundary_criteria + \" & \" + vacant_buildable_criteria + \" & \" + sf_mf_criteria + \" & \" + ready_to_forecast + \" & \" + condo_size_condition\n",
    "CSLT_Bonus_MF_condition       = \"(df['JURISDICTION'] == 'CSLT')\" + \" & \" + bonus_unit_criteria + \" & \" + trpa_boundary_criteria + \" & \" + vacant_buildable_criteria + \" & \" + sf_mf_criteria + \" & \" + ready_to_forecast + \" & \" + condo_size_condition\n",
    "CSLT_Bonus_infill_condition   = \"(df['JURISDICTION'] == 'CSLT')\" + \" & \" + bonus_unit_criteria + \" & \" + trpa_boundary_criteria + \" & \" + sf_mf_criteria + \" & \" + ready_to_forecast+ \" & \" + condo_size_condition\n",
    "\n",
    "DG_Bonus_SF_condition         = \"(df['JURISDICTION'] == 'DG')\" + \" & \" + bonus_unit_criteria + \" & \" + trpa_boundary_criteria + \" & \" + vacant_buildable_criteria + \" & \" + sf_mf_criteria + \" & \" + ready_to_forecast+ \" & \" + condo_size_condition\n",
    "DG_Bonus_MF_condition         = \"(df['JURISDICTION'] == 'DG')\" + \" & \" + bonus_unit_criteria + \" & \" +  trpa_boundary_criteria + \" & \" + vacant_buildable_criteria + \" & \" + sf_mf_criteria + \" & \" + ready_to_forecast+ \" & \" + condo_size_condition\n",
    "DG_Bonus_infill_condition     = \"(df['JURISDICTION'] == 'DG')\" + \" & \" + bonus_unit_criteria + \" & \" +  trpa_boundary_criteria +  \" & \" + sf_mf_criteria + \" & \" + ready_to_forecast + \" & \" + condo_size_condition\n",
    "\n",
    "PL_Bonus_SF_condition         = \"(df['JURISDICTION'] == 'PL')\" + \" & \" + bonus_unit_criteria + \" & \" + trpa_boundary_criteria + \" & \" + placer_vacant_buildable_criteria + \" & \" + sf_mf_criteria + \" & \" + ready_to_forecast+ \" & \" + condo_size_condition\n",
    "PL_Bonus_MF_condition         = \"(df['JURISDICTION'] == 'PL')\" + \" & \" + bonus_unit_criteria + \" & \" + trpa_boundary_criteria + \" & \" + placer_vacant_buildable_criteria + \" & \" + sf_only_criteria + \" & \" + ready_to_forecast+ \" & \" + condo_size_condition\n",
    "PL_Bonus_infill_condition     = \"(df['JURISDICTION'] == 'PL')\" + \" & \" + bonus_unit_criteria + \" & \" + trpa_boundary_criteria + \" & \" + sf_mf_criteria + \" & \" + ready_to_forecast+ \" & \" + condo_size_condition\n",
    "\n",
    "WA_Bonus_MF_condition         = \"(df['JURISDICTION'] == 'WA')\" + \" & \" + bonus_unit_criteria + \" & \" + trpa_boundary_criteria + \" & \" + vacant_buildable_criteria + \" & \" + sf_only_criteria + \" & \" + ready_to_forecast+ \" & \" + condo_size_condition\n",
    "WA_Bonus_SF_condition         = \"(df['JURISDICTION'] == 'WA')\" + \" & \" + bonus_unit_criteria + \" & \" + trpa_boundary_criteria + \" & \" + vacant_buildable_criteria + \" & \" + sf_only_criteria + \" & \" + ready_to_forecast+ \" & \" + condo_size_condition\n",
    "WA_Bonus_infill_condition     = \"(df['JURISDICTION'] == 'WA')\" + \" & \" + bonus_unit_criteria + \" & \" + trpa_boundary_criteria + \" & \" + sf_mf_criteria + \" & \" + ready_to_forecast+ \" & \" + condo_size_condition\n",
    "\n",
    "# jurisdiction general conditions\n",
    "CSLT_MF_condition             = \"(df['JURISDICTION'] == 'CSLT') & \" + trpa_boundary_criteria + \" & \" + vacant_buildable_criteria + \" & \" + sf_mf_criteria + \" & \" + ready_to_forecast + \" & \" + condo_size_condition\n",
    "CSLT_SF_condition             = \"(df['JURISDICTION'] == 'CSLT') & \" + trpa_boundary_criteria + \" & \" + vacant_buildable_criteria + \" & \" + sf_only_criteria + \" & \" + ready_to_forecast + \" & \" + condo_size_condition\n",
    "CSLT_infill_condition         = \"(df['JURISDICTION'] == 'CSLT') & \" + trpa_boundary_criteria + \" & \" + sf_mf_criteria + \" & \" + ready_to_forecast + \" & \" + condo_size_condition\n",
    "\n",
    "DG_MF_condition               = \"(df['JURISDICTION'] == 'DG') & \" + trpa_boundary_criteria + \" & \" + vacant_buildable_criteria + \" & \" + sf_mf_criteria + \" & \" + ready_to_forecast + \" & \" + condo_size_condition\n",
    "DG_SF_condition               = \"(df['JURISDICTION'] == 'DG') & \" + trpa_boundary_criteria + \" & \" + vacant_buildable_criteria + \" & \" + sf_only_criteria + \" & \" + ready_to_forecast + \" & \" + condo_size_condition\n",
    "DG_infill_condition           = \"(df['JURISDICTION'] == 'DG') & \" + trpa_boundary_criteria + \" & \" + sf_mf_criteria + \" & \" + ready_to_forecast + \" & \" + condo_size_condition\n",
    "\n",
    "EL_MF_condition               = \"(df['JURISDICTION'] == 'EL') & \" + trpa_boundary_criteria + \" & \" + vacant_buildable_criteria + \" & \" + sf_mf_criteria + \" & \" + ready_to_forecast + \" & \" + condo_size_condition  \n",
    "EL_SF_condition               = \"(df['JURISDICTION'] == 'EL') & \" + trpa_boundary_criteria + \" & \" + vacant_buildable_criteria + \" & \" + sf_only_criteria + \" & \" + ready_to_forecast + \" & \" + condo_size_condition\n",
    "EL_infill_condition           = \"(df['JURISDICTION'] == 'EL') & \" + trpa_boundary_criteria + \" & \" + sf_mf_criteria + \" & \" + ready_to_forecast + \" & \" + condo_size_condition\n",
    "\n",
    "PL_MF_condition               = \"(df['JURISDICTION'] == 'PL') & \" + trpa_boundary_criteria + \" & \" + placer_vacant_buildable_criteria + \" & \" + sf_mf_criteria + \" & \" + ready_to_forecast + \" & \" + condo_size_condition\n",
    "PL_SF_condition               = \"(df['JURISDICTION'] == 'PL') & \" + trpa_boundary_criteria + \" & \" + placer_vacant_buildable_criteria + \" & \" + sf_only_criteria + \" & \" + ready_to_forecast + \" & \" + condo_size_condition\n",
    "PL_infill_condition           = \"(df['JURISDICTION'] == 'PL') & \" + trpa_boundary_criteria + \" & \" + sf_mf_criteria + \" & \" + ready_to_forecast + \" & \" + condo_size_condition\n",
    "\n",
    "WA_MF_condition               = \"(df['JURISDICTION'] == 'WA') & \" + trpa_boundary_criteria + \" & \" + vacant_buildable_criteria + \" & \" + sf_mf_criteria + \" & \" + ready_to_forecast + \" & \" + condo_size_condition\n",
    "WA_SF_condition               = \"(df['JURISDICTION'] == 'WA') & \" + trpa_boundary_criteria + \" & \" + vacant_buildable_criteria + \" & \" + sf_only_criteria + \" & \" + ready_to_forecast + \" & \" + condo_size_condition\n",
    "WA_infill_condition           = \"(df['JURISDICTION'] == 'WA') & \" + trpa_boundary_criteria + \" & \" + sf_mf_criteria + \" & \" + ready_to_forecast + \" & \" + condo_size_condition\n",
    "\n",
    "# TRPA pool conditions\n",
    "# bonus unit conditions\n",
    "TRPA_Bonus_MF_condition       = bonus_unit_criteria + \" & \" + trpa_boundary_criteria + \" & \" + vacant_buildable_criteria + \" & \" + sf_mf_criteria + \" & \" + ready_to_forecast+ \" & \" + condo_size_condition\n",
    "TRPA_Bonus_SF_condition       = bonus_unit_criteria + \" & \" + trpa_boundary_criteria + \" & \" + vacant_buildable_criteria + \" & \" + sf_only_criteria + \" & \" + ready_to_forecast+ \" & \" + condo_size_condition\n",
    "TRPA_Bonus_infill_condition   = bonus_unit_criteria + \" & \" + trpa_boundary_criteria + \" & \" + sf_mf_criteria + \" & \" + ready_to_forecast+ \" & \" + condo_size_condition\n",
    "# general conditions\n",
    "TRPA_MF_condition             = trpa_boundary_criteria + \" & \" + vacant_buildable_criteria + \" & \" + sf_mf_criteria + \" & \" + ready_to_forecast+ \" & \" + condo_size_condition\n",
    "TRPA_SF_condition             = trpa_boundary_criteria + \" & \" + vacant_buildable_criteria + \" & \" + sf_only_criteria + \" & \" + ready_to_forecast+ \" & \" + condo_size_condition\n",
    "TRPA_infill_condition         = trpa_boundary_criteria + \" & \" + sf_mf_criteria + \" & \" + ready_to_forecast+ \" & \" + condo_size_condition\n",
    "\n",
    "# Town Center Pool Conditions\n",
    "TC_MF_condition               = trpa_boundary_criteria + \" & \" + towncenter_condition + \" & \" + vacant_buildable_criteria + \" & \" + sf_mf_criteria + \" & \" + ready_to_forecast + \" & \" + condo_size_condition\n",
    "TC_SF_condition               = trpa_boundary_criteria + \" & \" + towncenter_condition + \" & \" + vacant_buildable_criteria + \" & \" + sf_mf_criteria + \" & \" + ready_to_forecast + \" & \" + condo_size_condition\n",
    "TC_infill_condition           = trpa_boundary_criteria + \" & \" + towncenter_condition + \" & \" + sf_mf_criteria + \" & \" + ready_to_forecast + \" & \" + condo_size_condition\n",
    "\n",
    "# ADU Pool Conditions\n",
    "TRPA_ADU_condition            = trpa_boundary_criteria + \" & \" + adu_criteria + \" & \" + ready_to_forecast + \" & \" + condo_size_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = {\n",
    "                'CSLT_Bonus_SF'      : CSLT_Bonus_SF_condition, \n",
    "                'CSLT_Bonus_MF'      : CSLT_Bonus_MF_condition, \n",
    "                'CSLT_Bonus_Infill'  : CSLT_Bonus_infill_condition,\n",
    "                'DG_Bonus_SF'        : DG_Bonus_SF_condition,\n",
    "                'DG_Bonus_MF'        : DG_Bonus_MF_condition,\n",
    "                'DG_Bonus_Infill'    : DG_Bonus_infill_condition,\n",
    "                'PL_Bonus_SF'        : PL_Bonus_SF_condition,\n",
    "                'PL_Bonus_MF'        : PL_Bonus_MF_condition,\n",
    "                'PL_Bonus_Infill'    : PL_Bonus_infill_condition,\n",
    "                'WA_Bonus_SF'        : WA_Bonus_SF_condition,\n",
    "                'WA_Bonus_MF'        : WA_Bonus_MF_condition,\n",
    "                'WA_Bonus_Infil'     : WA_Bonus_infill_condition,\n",
    "                'CSLT_General_MF'    : CSLT_MF_condition,\n",
    "                'CSLT_General_SF'    : CSLT_SF_condition,\n",
    "                'CSLT_General_Infill': CSLT_infill_condition,\n",
    "                'DG_General_MF'      : DG_MF_condition,\n",
    "                'DG_General_SF'      : DG_SF_condition,\n",
    "                'DG_General_Infill'  : DG_infill_condition,\n",
    "                'EL_General_MF'      : EL_MF_condition,\n",
    "                'EL_General_SF'      : EL_SF_condition,\n",
    "                'EL_General_Infill'  : EL_infill_condition,\n",
    "                'PL_General_MF'      : PL_MF_condition,\n",
    "                'PL_General_SF'      : PL_SF_condition,\n",
    "                'PL_General_Infill'  : PL_infill_condition,\n",
    "                'WA_General_MF'      : WA_MF_condition,\n",
    "                'WA_General_SF'      : WA_SF_condition,\n",
    "                'WA_General_Infill'  : WA_infill_condition,\n",
    "                'TRPA_Bonus_MF'      : TRPA_Bonus_MF_condition,\n",
    "                'TRPA_Bonus_SF'      : TRPA_Bonus_SF_condition,\n",
    "                'TRPA_Bonus_Infill'  : TRPA_Bonus_infill_condition,\n",
    "                'TRPA_General_MF'    : TRPA_MF_condition,\n",
    "                'TRPA_General_SF'    : TRPA_SF_condition,\n",
    "                'TRPA_General_Infill': TRPA_infill_condition,\n",
    "                'TRPA_ADU'           : adu_criteria,\n",
    "                'TC_MF'              : TC_MF_condition,\n",
    "                'TC_SF'              : TC_SF_condition,\n",
    "                'TC_Infill'          : TC_infill_condition,\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check parcel conditions\n",
    "df_potential = pd.DataFrame()\n",
    "for key,value in conditions.items():\n",
    "    df = check_parcel_condition(sdfParcels, value)\n",
    "    df['Condition'] = key\n",
    "    df_potential = pd.concat([df_potential, df], axis=0)\n",
    "\n",
    "df_potential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Forecast Jurisdiction Pools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Jurisdictional Forecasting ##\n",
    "##-----------------------------------------------------------Bonus Unit Assignments-----------------------------------------------------------##\n",
    "## CSLT Bonus Unit Assignments ##\n",
    "# Assign Bonus Units to Multifamily zoned parcels within the Bonus Unit Boundary\n",
    "target_sum             = get_target_sum(dfPool, 'CSLT', 'Bonus Unit', 'MF')\n",
    "sdfParcels, df_summary = forecast_residential_units(sdfParcels, CSLT_Bonus_MF_condition, target_sum, 'CSLT Bonus Units MF')\n",
    "df_built_parcels = df_summary\n",
    "# Assign Bonus Units to Single Family only zoned parcels within the Bonus Unit Boundary\n",
    "target_sum             = get_target_sum(dfPool, 'CSLT', 'Bonus Unit', 'SF')\n",
    "sdfParcels, df_summary = forecast_residential_units(sdfParcels, CSLT_Bonus_SF_condition, target_sum, 'CSLT Bonus Units SF')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "# Assign Bonus Units to Developable Infill parcels within the Bonus Unit Boundary\n",
    "target_sum             = get_target_sum(dfPool, 'CSLT', 'Bonus Unit', 'Infill')\n",
    "sdfParcels, df_summary = forecast_residential_units_infill(sdfParcels, CSLT_Bonus_infill_condition, target_sum, 'CSLT Bonus Units Infill')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "\n",
    "## Douglas Bonus Unit Assignments ##\n",
    "# Assign Bonus Units to Multifamily zoned parcels within the Bonus Unit Boundary\n",
    "target_sum             = get_target_sum(dfPool, 'DG', 'Bonus Unit', 'MF')\n",
    "sdfParcels, df_summary = forecast_residential_units(sdfParcels, DG_Bonus_MF_condition, target_sum, 'DG Bonus Units MF')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "# Assign Bonus Units to Single Family only zoned parcels within the Bonus Unit Boundary\n",
    "target_sum             = get_target_sum(dfPool, 'DG', 'Bonus Unit', 'SF')\n",
    "sdfParcels, df_summary = forecast_residential_units(sdfParcels, DG_Bonus_SF_condition, target_sum, 'DG Bonus Units SF')\n",
    "# Assign Bonus Units to Developable Infill parcels within the Bonus Unit Boundary\n",
    "target_sum             = get_target_sum(dfPool, 'DG', 'Bonus Unit', 'Infill')\n",
    "sdfParcels, df_summary = forecast_residential_units_infill(sdfParcels, DG_Bonus_infill_condition, target_sum, 'DG Bonus Units Infill')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "\n",
    "## Placer Bonus Unit Assignments ##\n",
    "# Assign Bonus Units to Multifamily zoned parcels within the Bonus Unit Boundary\n",
    "target_sum             = get_target_sum(dfPool, 'PL', 'Bonus Unit', 'MF')\n",
    "sdfParcels, df_summary = forecast_residential_units(sdfParcels, PL_Bonus_MF_condition, target_sum, 'PL Bonus Units MF')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "# Assign Bonus Units to Single Family only zoned parcels within the Bonus Unit Boundary\n",
    "target_sum             = get_target_sum(dfPool, 'PL', 'Bonus Unit', 'SF')\n",
    "sdfParcels, df_summary = forecast_residential_units(sdfParcels, PL_Bonus_SF_condition, target_sum, 'PL Bonus Units SF')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "# Assign Bonus Units to Developable Infill parcels within the Bonus Unit Boundary\n",
    "target_sum             = get_target_sum(dfPool, 'PL', 'Bonus Unit', 'Infill')\n",
    "sdfParcels, df_summary = forecast_residential_units(sdfParcels, PL_Bonus_infill_condition, target_sum, 'PL Bonus Units Infill')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "\n",
    "## Washoe Bonus Unit Assignments ##\n",
    "# Assign Bonus Units to Multifamily zoned parcels within the Bonus Unit Boundary\n",
    "target_sum             = get_target_sum(dfPool, 'WA', 'Bonus Unit', 'MF')\n",
    "sdfParcels, df_summary = forecast_residential_units(sdfParcels, WA_Bonus_MF_condition, target_sum, 'WA Bonus Units SF')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "# Assign Bonus Units to Single Family only zoned parcels within the Bonus Unit Boundary\n",
    "target_sum             = get_target_sum(dfPool, 'WA', 'Bonus Unit', 'SF')\n",
    "sdfParcels, df_summary = forecast_residential_units(sdfParcels, WA_Bonus_SF_condition, target_sum, 'WA Bonus Units SF')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "# Assign Bonus Units to Developable Infill parcels within the Bonus Unit Boundary\n",
    "target_sum             = get_target_sum(dfPool, 'WA', 'Bonus Unit', 'Infill')\n",
    "sdfParcels, df_summary = forecast_residential_units_infill(sdfParcels, WA_Bonus_infill_condition, target_sum, 'WA Bonus Units Infill')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "\n",
    "## ----------------------------------------------------General Unit Assignments---------------------------------------------------- ##\n",
    "## CSTL General Unit Assignments ##\n",
    "# Assign General Jurisdiction Units to Multifamily zoned parcels\n",
    "target_sum             = get_target_sum(dfPool, 'CSLT', 'General', 'MF')\n",
    "sdfParcels, df_summary = forecast_residential_units(sdfParcels, CSLT_MF_condition, target_sum, 'CSLT General Units MF')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "# Assign General Jurisdiction Units to Single Family only zoned parcels\n",
    "target_sum             = get_target_sum(dfPool, 'CSLT', 'General', 'SF')\n",
    "sdfParcels, df_summary = forecast_residential_units(sdfParcels, CSLT_SF_condition, target_sum, 'CSLT General Units SF')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "# Assign General Jurisdiction Units to Developable Infill parcels\n",
    "target_sum             = get_target_sum(dfPool, 'CSLT', 'General', 'Infill')\n",
    "sdfParcels, df_summary = forecast_residential_units_infill(sdfParcels, CSLT_Infill_condition, target_sum, 'CSLT General Units Infill')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "\n",
    "## El Dorado General Unit Assignments ##\n",
    "# Assign General Jurisdiction Units to Multifamily zoned parcels\n",
    "target_sum             = get_target_sum(dfPool, 'EL', 'General', 'MF')\n",
    "sdfParcels, df_summary = forecast_residential_units(sdfParcels, EL_MF_condition, target_sum, 'EL General Units MF')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "# Assign General Jurisdiction Units to Single Family only zoned parcels\n",
    "target_sum             = get_target_sum(dfPool, 'EL', 'General', 'SF')\n",
    "sdfParcels, df_summary = forecast_residential_units(sdfParcels, EL_SF_condition, target_sum, 'EL General Units SF')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "# Assign General Jurisdiction Units to Developable Infill parcels\n",
    "target_sum             = get_target_sum(dfPool, 'EL', 'General', 'Infill')\n",
    "sdfParcels, df_summary = forecast_residential_units_infill(sdfParcels, EL_infill_condition, target_sum, 'EL General Units Infill')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "\n",
    "# Placer General Unit Assignments\n",
    "# Assign General Jurisdiction Units to Multifamily zoned parcels\n",
    "target_sum             = get_target_sum(dfPool, 'PL', 'General', 'MF')\n",
    "sdfParcels, df_summary = forecast_residential_units(sdfParcels, PL_MF_condition, target_sum, 'PL General Units MF')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "# Assign General Jurisdiction Units to Single Family only zoned parcels\n",
    "target_sum             = get_target_sum(dfPool, 'PL', 'General', 'SF')\n",
    "sdfParcels, df_summary = forecast_residential_units(sdfParcels, PL_SF_condition, target_sum, 'PL General Units SF')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "# Assign General Jurisdiction Units to Developable Infill parcels\n",
    "target_sum             = get_target_sum(dfPool, 'PL', 'General', 'Infill')\n",
    "sdfParcels, df_summary = forecast_residential_units_infill(sdfParcels, PL_infill_condition, target_sum, 'PL General Units Infill')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "\n",
    "# Douglas General Unit Assignments\n",
    "# Assign General Jurisdiction Units to Multifamily zoned parcels\n",
    "target_sum             = get_target_sum(dfPool, 'DG', 'General', 'MF')\n",
    "sdfParcels, df_summary = forecast_residential_units(sdfParcels, DG_MF_condition, target_sum, 'DG General Units MF')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "# Assign General Jurisdiction Units to Single Family only zoned parcels\n",
    "target_sum             = get_target_sum(dfPool, 'DG', 'General', 'SF')\n",
    "sdfParcels, df_summary = forecast_residential_units(sdfParcels, DG_SF_condition, target_sum, 'DG General Units SF')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "# Assign General Jurisdiction Units to Developable Infill parcels\n",
    "target_sum             = get_target_sum(dfPool, 'DG', 'General', 'Infill')\n",
    "sdfParcels, df_summary = forecast_residential_units_infill(sdfParcels, DG_infill_condition, target_sum, 'DG General Units Infill')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "\n",
    "# Washoe General Unit Assignments\n",
    "# Assign General Jurisdiction Units to Multifamily zoned parcels \n",
    "target_sum             = get_target_sum(dfPool, 'WA', 'General', 'MF')\n",
    "sdfParcels, df_summary = forecast_residential_units(sdfParcels, WA_MF_condition, target_sum, 'WA General Units MF')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "# Assign General Jurisdiction Units to Single Family only zoned parcels\n",
    "target_sum             = get_target_sum(dfPool, 'WA', 'General', 'SF')\n",
    "sdfParcels, df_summary = forecast_residential_units(sdfParcels, WA_SF_condition, target_sum, 'WA General Units SF')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "# Assign General Jurisdiction Units to Developable Infill parcels\n",
    "target_sum             = get_target_sum(dfPool, 'WA', 'General', 'Infill')\n",
    "sdfParcels, df_summary = forecast_residential_units_infill(sdfParcels, WA_infill_condition, target_sum, 'WA General Units Infill')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "\n",
    "df_built_parcels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Forecast TRPA Pools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRPA Unit Pool Assignments ##\n",
    "##-----------------------------------------------------------Bonus Unit Assignments-----------------------------------------------------------##\n",
    "## TRPA Bonus Unit Assignments ##\n",
    "# Assign Bonus Units to Multifamily zoned parcels within the Bonus Unit Boundary\n",
    "target_sum             = get_target_sum(dfPool, 'TRPA', 'Bonus Unit', 'MF')\n",
    "sdfParcels, df_summary = forecast_residential_units(sdfParcels, TRPA_Bonus_MF_condition, target_sum, 'TRPA Bonus Units MF')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "# Assign Bonus Units to Single Family only zoned parcels within the Bonus Unit Boundary\n",
    "target_sum             = get_target_sum(dfPool, 'TRPA', 'Bonus Unit', 'SF')\n",
    "sdfParcels, df_summary = forecast_residential_units(sdfParcels, TRPA_Bonus_SF_condition, target_sum, 'TRPA Bonus Units SF')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "# Assign Bonus Units to Developable Infill parcels within the Bonus Unit Boundary\n",
    "target_sum             = get_target_sum(dfPool, 'TRPA', 'Bonus Unit', 'Infill')\n",
    "sdfParcels, df_summary = forecast_residential_units_infill(sdfParcels, TRPA_Bonus_infill_condition, target_sum, 'TRPA Bonus Units Infill')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "\n",
    "## ---------------------------------------------------------TRPA General Unit Assignments--------------------------------------------------------- ##\n",
    "# Assign General Jurisdiction Units to Multifamily zoned parcels\n",
    "target_sum             = get_target_sum(dfPool, 'TRPA', 'General', 'MF')\n",
    "sdfParcels, df_summary = forecast_residential_units(sdfParcels, TRPA_MF_condition, target_sum, 'TRPA General Units MF')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "# Assign General Jurisdiction Units to Single Family only zoned parcels\n",
    "target_sum             = get_target_sum(dfPool, 'TRPA', 'General', 'SF')\n",
    "sdfParcels, df_summary = forecast_residential_units(sdfParcels, TRPA_SF_condition, target_sum, 'TRPA General Units SF')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "# Assign General Jurisdiction Units to Developable Infill parcels\n",
    "target_sum             = get_target_sum(dfPool, 'TRPA', 'General', 'Infill')\n",
    "sdfParcels, df_summary = forecast_residential_units_infill(sdfParcels, TRPA_infill_condition, target_sum, 'TRPA General Units Infill')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "\n",
    "## TRPA ADU Unit Assignments ##\n",
    "# Assign ADU Units to parcels\n",
    "target_sum             = get_target_sum(dfPool, 'TRPA', 'ADU', 'ADU')\n",
    "sdfParcels, df_summary = forecast_residential_units(sdfParcels, TRPA_ADU_condition, target_sum, 'TRPA ADU Units')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "\n",
    "# summarize total units forecasted\n",
    "df_built_parcels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Assign the Remainders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use df_built_parcels to set new infill target_sum\n",
    "df_remaining = df_built_parcels.loc[df_built_parcels.Total_Remaining_Units > 0]\n",
    "df_remaining.Reason.to_list() \n",
    "\n",
    "# get first text before first space\n",
    "df_remaining['Jurisdiction'] = df_remaining['Reason'].str.split(' ').str[0]\n",
    "df_remaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##------------------------------------ Infill Forecasting remaining units from other Pools ------------------------------------##\n",
    "\n",
    "# Forecast based on target sum of remaining units but using infill function and condition\n",
    "target_sum = df_remaining.loc[df_remaining.Reason == 'WA Bonus Units SF', 'Total_Remaining_Units'].values[0]\n",
    "sdfParcels, df_summary = forecast_residential_units_infill(sdfParcels, WA_Bonus_infill_condition, target_sum, 'WA Bonus Units Infill')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "\n",
    "target_sum = df_remaining.loc[df_remaining.Reason == 'EL General Units MF', 'Total_Remaining_Units'].values[0]\n",
    "sdfParcels, df_summary = forecast_residential_units_infill(sdfParcels, EL_infill_condition, target_sum, 'EL General Units Infill')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "\n",
    "target_sum = df_remaining.loc[df_remaining.Reason == 'PL General Units MF', 'Total_Remaining_Units'].values[0]\n",
    "sdfParcels, df_summary = forecast_residential_units_infill(sdfParcels, PL_infill_condition, target_sum, 'PL General Units Infill')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "\n",
    "target_sum = df_remaining.loc[df_remaining.Reason == 'DG General Units MF', 'Total_Remaining_Units'].values[0]\n",
    "sdfParcels, df_summary = forecast_residential_units(sdfParcels, DG_infill_condition, target_sum, 'DG General Units Infill')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "\n",
    "target_sum = df_remaining.loc[df_remaining.Reason == 'WA General Units MF', 'Total_Remaining_Units'].values[0]\n",
    "sdfParcels, df_summary = forecast_residential_units_infill(sdfParcels, WA_infill_condition, target_sum, 'WA General Units Infill')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "\n",
    "target_sum = df_remaining.loc[df_remaining.Reason == 'WA General Units SF', 'Total_Remaining_Units'].values[0]\n",
    "sdfParcel, df_summary = forecast_residential_units_infill(sdfParcels, WA_infill_condition, target_sum, 'WA General Units Infill')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "\n",
    "# TRPA General Remaining Units\n",
    "target_sum = df_remaining.loc[df_remaining.Reason == 'TRPA General Units MF', 'Total_Remaining_Units'].values[0]\n",
    "sdfParcels, df_summary = forecast_residential_units_infill(sdfParcels, TRPA_infill_condition, target_sum, 'TRPA General Units Infill')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "\n",
    "df_built_parcels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign ADUs to existing residential parcels residential units=1 and ADU_ALLOWED = Yes\n",
    "target_sum = 4385 - sdfParcels.FORECASTED_RESIDENTIAL_UNITS.sum()\n",
    "sdfParcels, df_summary = forecast_residential_units(sdfParcels, TRPA_ADU_condition, target_sum, 'TRPA ADU Units')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Check Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPoolMelt = dfPool.melt(id_vars=['Jurisdiction', 'Unit_Pool'], value_vars=['Future_Units_Adjusted_MF', 'Future_Units_Adjusted_SF', 'Future_Units_Adjusted_Infill'])\n",
    "# drop Future_Units_Adjusted_ from variable\n",
    "dfPoolMelt['variable'] = dfPoolMelt['variable'].str.replace('Future_Units_Adjusted_', '')\n",
    "\n",
    "dfPoolMelt['Unit_Pool'] = dfPoolMelt['Jurisdiction'] + ' ' + dfPoolMelt['Unit_Pool']\n",
    "dfPoolMelt.rename(columns={'variable': 'Reason', 'value': 'Units'}, inplace=True)\n",
    "\n",
    "dfForecastGroup = sdfParcels.groupby(['FORECAST_REASON'])['FORECASTED_RESIDENTIAL_UNITS'].sum().reset_index()\n",
    "# split last FORECAST Reason into two columns based on last space in string\n",
    "dfForecastGroup['Reason'] = dfForecastGroup['FORECAST_REASON'].str.split(' ').str[-1]\n",
    "dfForecastGroup['Jurisdiction'] = dfForecastGroup['FORECAST_REASON'].str.split(' ').str[0]\n",
    "# if FORECAST_REASON valie contains 'Bonus' then set Unit Pool to Bonus Units\n",
    "dfForecastGroup.loc[dfForecastGroup['FORECAST_REASON'].str.contains('Bonus'), 'Unit_Pool'] = dfForecastGroup.Jurisdiction + ' ' + 'Bonus Unit'\n",
    "# if FORECAST_REASON valie contains 'General' then set Unit Pool to General Units\n",
    "dfForecastGroup.loc[dfForecastGroup['FORECAST_REASON'].str.contains('General'), 'Unit_Pool'] = dfForecastGroup.Jurisdiction + ' ' + 'General'\n",
    "dfMerge = dfForecastGroup.merge(dfPoolMelt, on=['Unit_Pool', 'Reason'], how='left')\n",
    "dfMerge['Unit_Diff'] = dfMerge['FORECASTED_RESIDENTIAL_UNITS'] - dfMerge['Units']\n",
    "dfMerge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Assign Forecast Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Assigning Development Year to Parcels ##\n",
    "# Get total development by 2035\n",
    "TotalDevelopment = dfResZoned.Future_Units.sum()\n",
    "Development_2035 = (TotalDevelopment*.46).astype(int)\n",
    "sdfParcels['Development_Year']=None\n",
    "#Assining all development that's currently in the works as being cone by 2035\n",
    "sdfParcels.loc[sdfParcels['FORECAST_REASON'] == 'Assigned', 'Development_Year'] = 2035\n",
    "RemainingDevelopment_2035 = Development_2035 - sdfParcels.loc[sdfParcels['FORECAST_REASON'] == 'Assigned', 'FORECASTED_RESIDENTIAL_UNITS'].sum()\n",
    "\n",
    "Development_2035_Condition = sdfParcels['FORECASTED_RESIDENTIAL_UNITS'].where(sdfParcels['FORECAST_REASON'] != 'Assigned').cumsum()\n",
    "sdfParcels.loc[Development_2035_Condition < RemainingDevelopment_2035, 'Development_Year'] = 2035\n",
    "sdfParcels.loc[(sdfParcels['FORECAST_REASON']!= '') & (sdfParcels['Development_Year'].isnull()), 'Development_Year'] = 2050\n",
    "development_year = sdfParcels.groupby('Development_Year')['FORECASTED_RESIDENTIAL_UNITS'].sum()\n",
    "development_year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assign Occupancy Rate to all forecasted residential parcels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdfParcels = pd.read_pickle(parcel_pickle_part2)\n",
    "# filter to FORECAST_YEAR = 2035\n",
    "sdfParcels = sdfParcels.loc[sdfParcels['Development_Year'] == 2050]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdfParcels['FORECASTED_RES_OCCUPANCY_RATE'] = 0\n",
    "# map lookup known project occupancy rates to parcels\n",
    "sdfParcels['FORECASTED_RES_OCCUPANCY_RATE'] = sdfParcels['APN'].map(dict(zip(dfResAssigned.APN, dfResAssigned['Occupancy_Rate'])))\n",
    "sdfParcels.FORECAST_REASON.value_counts()\n",
    "# if FORECAST_REASON has the word 'Bonus' in it set occupancy rate to 100%\n",
    "sdfParcels.loc[sdfParcels['FORECAST_REASON'].fillna('').str.contains('Bonus'), 'FORECASTED_RES_OCCUPANCY_RATE'] = 1\n",
    "# if FORECAST_REASON has the word 'CTC' in it set occupancy rate to 100%\n",
    "sdfParcels.loc[sdfParcels['FORECAST_REASON'].fillna('').str.contains('CTC'), 'FORECASTED_RES_OCCUPANCY_RATE'] = 1\n",
    "# if FORECAST_REASON has the word 'General' and housing zoning is SF_only in it set occupancy rate to 35\n",
    "sdfParcels.loc[(sdfParcels['FORECAST_REASON'].fillna('').str.contains('General')), 'FORECASTED_RES_OCCUPANCY_RATE'] = 0.35"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assing Household Income Category - Low, Medium, High"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdfParcels['FORECASTED_RES_INCOME_LOW']     = 0.0\n",
    "sdfParcels['FORECASTED_RES_INCOME_MEDIUM']  = 0.0\n",
    "sdfParcels['FORECASTED_RES_INCOME_HIGH']    = 0.0\n",
    "\n",
    "# map lookup known project income levels to parcels\n",
    "sdfParcels['FORECAST_RES_INCOME_CATEGORY']     = sdfParcels.APN.map(dict(zip(dfResAssigned.APN, dfResAssigned['HH Income Category'])))\n",
    "# change 'Achievable' to 'Medium' and 'Affodaable to 'Low'\n",
    "sdfParcels.loc[sdfParcels['FORECAST_RES_INCOME_CATEGORY'] == 'Achievable', 'FORECAST_RES_INCOME_CATEGORY'] = 'Medium'\n",
    "sdfParcels.loc[sdfParcels['FORECAST_RES_INCOME_CATEGORY'] == 'Affordable', 'FORECAST_RES_INCOME_CATEGORY'] = 'Low'\n",
    "\n",
    "# def function to if income category is low, medium, or high income field to 1\n",
    "def income_category(df, category):\n",
    "    df.loc[df['FORECAST_RES_INCOME_CATEGORY'] == category, 'FORECASTED_RES_INCOME_' + str(category).upper()] = 1\n",
    "    return df\n",
    "\n",
    "for category in ['Low', 'Medium', 'High']:\n",
    "    sdfParcels = income_category(sdfParcels, category)\n",
    "\n",
    "# for FORECAST_REASON with 'Bonus' set low income to 1\n",
    "sdfParcels.loc[sdfParcels['FORECAST_REASON'].fillna('').str.contains('Bonus'), 'FORECASTED_RES_INCOME_LOW'] = 0.78\n",
    "sdfParcels.loc[sdfParcels['FORECAST_REASON'].fillna('').str.contains('Bonus'), 'FORECASTED_RES_INCOME_MEDIUM'] = 0.2\n",
    "sdfParcels.loc[sdfParcels['FORECAST_REASON'].fillna('').str.contains('Bonus'), 'FORECASTED_RES_INCOME_HIGH'] = 0.02\n",
    "\n",
    "# for FORECAST_REASON with 'General' and housing zoning is SF_only set low income to 1\n",
    "sdfParcels.loc[(sdfParcels['FORECAST_REASON'].fillna('').str.contains('General')), 'FORECASTED_RES_INCOME_LOW'] = 0.01\n",
    "sdfParcels.loc[(sdfParcels['FORECAST_REASON'].fillna('').str.contains('General')), 'FORECASTED_RES_INCOME_MEDIUM'] = 0.02\n",
    "sdfParcels.loc[(sdfParcels['FORECAST_REASON'].fillna('').str.contains('General')), 'FORECASTED_RES_INCOME_HIGH'] = 0.97\n",
    "\n",
    "# assigne income levels to parcels with 'ADU' in FORECAST_REASON\n",
    "sdfParcels.loc[sdfParcels['FORECAST_REASON'].fillna('').str.contains('ADU'), 'FORECASTED_RES_INCOME_LOW'] = 0.5\n",
    "sdfParcels.loc[sdfParcels['FORECAST_REASON'].fillna('').str.contains('ADU'), 'FORECASTED_RES_INCOME_MEDIUM'] = 0.5\n",
    "sdfParcels.loc[sdfParcels['FORECAST_REASON'].fillna('').str.contains('ADU'), 'FORECASTED_RES_INCOME_HIGH'] = 0.0\n",
    "\n",
    "# for FORECAST_REASON with 'CTC' set low income to 1\n",
    "sdfParcels.loc[sdfParcels['FORECAST_REASON'].fillna('').str.contains('CTC'), 'FORECASTED_RES_INCOME_LOW'] = 1\n",
    "\n",
    "sdfParcels['FORECASTED_RES_INCOME_LOW_UNITS']    = sdfParcels['FORECASTED_RES_INCOME_LOW'] * sdfParcels['FORECASTED_RESIDENTIAL_UNITS']\n",
    "sdfParcels['FORECASTED_RES_INCOME_MEDIUM_UNITS'] = sdfParcels['FORECASTED_RES_INCOME_MEDIUM'] * sdfParcels['FORECASTED_RESIDENTIAL_UNITS']\n",
    "sdfParcels['FORECASTED_RES_INCOME_HIGH_UNITS']   = sdfParcels['FORECASTED_RES_INCOME_HIGH'] * sdfParcels['FORECASTED_RESIDENTIAL_UNITS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bring in the TAZ s\n",
    "socio            = 'TravelDemandModel\\\\2022\\\\data\\\\processed_data\\\\SocioEcon_Summer.csv'\n",
    "socio_path       = local_path.parents[2].joinpath(socio)\n",
    "dfSocio          = pd.read_csv(socio_path)\n",
    "\n",
    "# rename columns to taz to TAZ\n",
    "dfSocio.rename(columns={'taz': 'TAZ'}, inplace=True)\n",
    "# group by TAZ\n",
    "sdfParcels['FORECASTED_OCCUPIED_UNITS'] = sdfParcels['FORECASTED_RESIDENTIAL_UNITS'] * sdfParcels['FORECASTED_RES_OCCUPANCY_RATE']\n",
    "df = sdfParcels.loc[sdfParcels['FORECASTED_RESIDENTIAL_UNITS'] > 0]\n",
    "dfTAZ_Summary = df.groupby(['TAZ']).agg({'FORECASTED_RESIDENTIAL_UNITS': 'sum',\n",
    "                                                 'FORECASTED_OCCUPIED_UNITS':'sum', \n",
    "                                                 'FORECASTED_RES_INCOME_LOW_UNITS':'sum', 'FORECASTED_RES_INCOME_MEDIUM_UNITS':'sum',\n",
    "                                                 'FORECASTED_RES_INCOME_HIGH_UNITS':'sum'}).reset_index()\n",
    "\n",
    "# merge TAZ summary with socio data\n",
    "dfTAZ_Summary = dfTAZ_Summary.merge(dfSocio, on='TAZ', how='left')\n",
    "\n",
    "dfTAZ_Summary['TOTAL_FORECASTED_UNITS_LOW_INCOME'] = dfTAZ_Summary['FORECASTED_RES_INCOME_LOW_UNITS'] + dfTAZ_Summary['occ_units_low_inc']\n",
    "dfTAZ_Summary['TOTAL_FORECASTED_UNITS_MED_INCOME'] = dfTAZ_Summary['FORECASTED_RES_INCOME_MEDIUM_UNITS'] + dfTAZ_Summary['occ_units_med_inc']\n",
    "dfTAZ_Summary['TOTAL_FORECASTED_UNITS_HIGH_INCOME'] = dfTAZ_Summary['FORECASTED_RES_INCOME_HIGH_UNITS'] + dfTAZ_Summary['occ_units_high_inc']\n",
    "dfTAZ_Summary['NEW_OCCUPANCY_RATE'] = (dfTAZ_Summary['FORECASTED_OCCUPIED_UNITS'] + dfTAZ_Summary['total_occ_units'])/ (dfTAZ_Summary['total_residential_units'] + dfTAZ_Summary['FORECASTED_RESIDENTIAL_UNITS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to pickle\n",
    "taz_summary_2035_pickle = data_dir / 'taz_summary_2035.pickle'\n",
    "taz_summary_2050_pickle = data_dir / 'taz_summary_2050.pickle'\n",
    "# dfTAZ_Summary.to_pickle(taz_summary_2035_pickle)\n",
    "# dfTAZ_Summary.to_csv(data_dir / 'taz_summary_2035.csv')\n",
    "dfTAZ_Summary.to_pickle(taz_summary_2050_pickle)\n",
    "dfTAZ_Summary.to_csv(data_dir / 'taz_summary_2050.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### QA Extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "built_units = sdfParcels.groupby('FORECAST_REASON').agg({'FORECASTED_RESIDENTIAL_UNITS':'sum'})\n",
    "dfResZoned = dfPool.copy()\n",
    "# Create a dictionary to map the forecast reason to the Jurisdiction and Unit Pool\n",
    "Forecast_Reason_lookup = {'CSLT Bonus Units Built':{'Jurisdiction':'CSLT', 'Unit_Pool':'Bonus Unit'},\n",
    "                          'CSLT General Units Built':{'Jurisdiction':'CSLT', 'Unit_Pool':'General'},\n",
    "                          'EL General Units Built':{'Jurisdiction':'EL', 'Unit_Pool':'General'},\n",
    "                          'PL Bonus Units Built':{'Jurisdiction':'PL', 'Unit_Pool':'Bonus Unit'},\n",
    "                          'PL General Units Built':{'Jurisdiction':'PL', 'Unit_Pool':'General'},\n",
    "                          'WA Bonus Units Built':{'Jurisdiction':'WA', 'Unit_Pool':'Bonus Unit'},\n",
    "                          'WA General Units Built':{'Jurisdiction':'WA', 'Unit_Pool':'General'},\n",
    "                          'DG Bonus Units Built':{'Jurisdiction':'DG', 'Unit_Pool':'Bonus Unit'},\n",
    "                          'DG General Units Built':{'Jurisdiction':'DG', 'Unit_Pool':'General'},\n",
    "                          'TRPA Bonus Units Built':{'Jurisdiction':'TRPA', 'Unit_Pool':'Bonus Unit'},\n",
    "                          'TRPA General Units Built':{'Jurisdiction':'TRPA', 'Unit_Pool':'General'},\n",
    "                          'ADU Units Built':{'Jurisdiction':'TRPA', 'Unit_Pool':'ADU'}}\n",
    "# Map 'Jurisdiction' and 'Unit_Pool' separately from the dictionary\n",
    "built_units['Jurisdiction'] = built_units.index.map(lambda x: Forecast_Reason_lookup.get(x, {}).get('Jurisdiction'))\n",
    "built_units['Unit_Pool'] = built_units.index.map(lambda x: Forecast_Reason_lookup.get(x, {}).get('Unit_Pool'))\n",
    "unit_comparison = built_units.merge(dfResZoned, how='left', on=['Jurisdiction', 'Unit_Pool'])\n",
    "unit_comparison['Difference'] = unit_comparison['Future_Units_Adjusted'] - unit_comparison['FORECASTED_RESIDENTIAL_UNITS']\n",
    "unit_comparison.to_csv('unit_comparison.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forecasted residential uints by location to twon center\n",
    "sdfParcels.groupby(['LOCATION_TO_TOWNCENTER','FORECAST_REASON'])['FORECASTED_RESIDENTIAL_UNITS'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gropu by TAZ and sum forecasted residential units and residential units\n",
    "# Forecast year total residential units by TAZ\n",
    "sdfParcels.groupby('TAZ')[['FORECASTED_RESIDENTIAL_UNITS', 'Residential_Units']].sum().reset_index()\n",
    "# total units with forecast year 2035 and 2050\n",
    "sdfParcels.groupby('Development_Year')[['FORECASTED_RESIDENTIAL_UNITS', 'Residential_Units']].sum().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tourist Accommodation Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lookup lists\n",
    "tau_assigned_lookup = \"Lookup_Lists/forecast_tourist_assigned_units.csv\"\n",
    "# get assigned units lookup as data frames\n",
    "dfTouristAssigned = pd.read_csv(tau_assigned_lookup)\n",
    "# assign tourist units to parcels\n",
    "sdfParcels['FORECASTED_TOURIST_UNITS'] = 0\n",
    "# set tourist units to assigned total\n",
    "sdfParcels['FORECASTED_TOURIST_UNITS'] = sdfParcels.APN.map(dict(zip(dfTouristAssigned.APN, dfTouristAssigned['Unit_Pool'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commercial Floor Area Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lookup lists\n",
    "cfa_assigned_lookup = \"Lookup_Lists/forecast_commercial_assigned_units.csv\"\n",
    "# get zoned units lookups as data frames\n",
    "dfCommercialAssigned = pd.read_csv(cfa_assigned_lookup)\n",
    "# set commercial floor area to assigned total\n",
    "sdfParcels['FORECASTED_COMMERCIAL_FLOOR_AREA'] = 0\n",
    "sdfParcels['FORECASTED_COMMERCIAL_FLOOR_AREA'] = sdfParcels.APN.map(dict(zip(dfCommercialAssigned.APN, dfCommercialAssigned['NEW_CFA'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to pickle\n",
    "sdfParcels.to_pickle(parcel_pickle_part2)\n",
    "# to csv\n",
    "sdfParcels.to_csv(data_dir/'Parcels_Forecast.csv', index=False)\n",
    "# to feature class\n",
    "sdfParcels.spatial.to_featureclass(Path(gdb)/'Parcel_Forecast')\n",
    "\n",
    "# Summarize Existing and Forecasted Units by Jurisdiction and Unit Pool by TAZ\n",
    "dfTAZ = sdfParcels.groupby('TAZ')[['FORECASTED_RESIDENTIAL_UNITS', 'Residential_Units']].sum().reset_index()\n",
    "dfTAZ.to_csv(data_dir/'TAZ_Units.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arcgispro-py3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
