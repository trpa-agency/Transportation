{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tahoe Regional Transportation Plan Forecasting\n",
    "> Data Engineering Tasks\n",
    "* Residential development forecasting for 2035 and 2050"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import os\n",
    "import arcpy\n",
    "from utils import *\n",
    "import numpy as np\n",
    "import pickle\n",
    "# external connection packages\n",
    "from sqlalchemy.engine import URL\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# pandas options\n",
    "pd.options.mode.copy_on_write = True\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.options.display.max_columns = 999\n",
    "pd.options.display.max_rows    = 999\n",
    "\n",
    "# my workspace \n",
    "workspace = r\"C:\\Users\\mbindl\\Desktop\\Workspace.gdb\"\n",
    "# current working directory\n",
    "local_path = pathlib.Path().absolute()\n",
    "# set data path as a subfolder of the current working directory TravelDemandModel\\2022\\\n",
    "data_dir = local_path.parents[0] / 'data'\n",
    "# folder to save processed data\n",
    "out_dir  = local_path.parents[0] / 'data/processed_data'\n",
    "# workspace gdb for stuff that doesnt work in memory\n",
    "# gdb = os.path.join(local_path,'Workspace.gdb')\n",
    "gdb = workspace\n",
    "# set environement workspace to in memory \n",
    "arcpy.env.workspace = 'memory'\n",
    "# # clear memory workspace\n",
    "# arcpy.management.Delete('memory')\n",
    "\n",
    "# overwrite true\n",
    "arcpy.env.overwriteOutput = True\n",
    "# Set spatial reference to NAD 1983 UTM Zone 10N\n",
    "sr = arcpy.SpatialReference(26910)\n",
    "\n",
    "# get parcels from the database\n",
    "# network path to connection files\n",
    "filePath = \"F:/GIS/PARCELUPDATE/Workspace/\"\n",
    "# database file path \n",
    "sdeBase    = os.path.join(filePath, \"Vector.sde\")\n",
    "sdeCollect = os.path.join(filePath, \"Collection.sde\")\n",
    "sdeTabular = os.path.join(filePath, \"Tabular.sde\")\n",
    "sdeEdit    = os.path.join(filePath, \"Edit.sde\")\n",
    "\n",
    "# Pickle variables\n",
    "# part 1 - spatial joins and new categorical fields\n",
    "parcel_pickle_part1    = data_dir / 'parcel_pickle1.pkl'\n",
    "# part 2 - forecasting applied\n",
    "parcel_pickle_part2    = data_dir / 'parcel_pickle2.pkl'\n",
    "\n",
    "# columsn to list\n",
    "initial_columns = [ 'APN',\n",
    "                    'APO_ADDRESS',\n",
    "                    'Residential_Units',\n",
    "                    'TouristAccommodation_Units',\n",
    "                    'CommercialFloorArea_SqFt',\n",
    "                    'YEAR',\n",
    "                    'JURISDICTION',\n",
    "                    'COUNTY',\n",
    "                    'OWNERSHIP_TYPE',\n",
    "                    'COUNTY_LANDUSE_DESCRIPTION',\n",
    "                    'EXISTING_LANDUSE',\n",
    "                    'REGIONAL_LANDUSE',\n",
    "                    'YEAR_BUILT',\n",
    "                    'PLAN_ID',\n",
    "                    'PLAN_NAME',\n",
    "                    'ZONING_ID',\n",
    "                    'ZONING_DESCRIPTION',\n",
    "                    'TOWN_CENTER',\n",
    "                    'LOCATION_TO_TOWNCENTER',\n",
    "                    'TAZ',\n",
    "                    'PARCEL_ACRES',\n",
    "                    'PARCEL_SQFT',\n",
    "                    'WITHIN_BONUSUNIT_BNDY',\n",
    "                    'WITHIN_TRPA_BNDY',\n",
    "                    'SHAPE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conn(db):\n",
    "    # Get database user and password from environment variables on machine running script\n",
    "    db_user             = os.environ.get('DB_USER')\n",
    "    db_password         = os.environ.get('DB_PASSWORD')\n",
    "    # driver is the ODBC driver for SQL Server\n",
    "    driver              = 'ODBC Driver 17 for SQL Server'\n",
    "    # server names are\n",
    "    sql_12              = 'sql12'\n",
    "    sql_14              = 'sql14'\n",
    "    # make it case insensitive\n",
    "    db = db.lower()\n",
    "    # make sql database connection with pyodbc\n",
    "    if db   == 'sde_tabular':\n",
    "        connection_string = f\"DRIVER={driver};SERVER={sql_12};DATABASE={db};UID={db_user};PWD={db_password}\"\n",
    "        connection_url = URL.create(\"mssql+pyodbc\", query={\"odbc_connect\": connection_string})\n",
    "        engine = create_engine(connection_url)\n",
    "    elif db == 'tahoebmpsde':\n",
    "        connection_string = f\"DRIVER={driver};SERVER={sql_14};DATABASE={db};UID={db_user};PWD={db_password}\"\n",
    "        connection_url = URL.create(\"mssql+pyodbc\", query={\"odbc_connect\": connection_string})\n",
    "        engine = create_engine(connection_url)\n",
    "    elif db == 'sde':\n",
    "        connection_string = f\"DRIVER={driver};SERVER={sql_12};DATABASE={db};UID={db_user};PWD={db_password}\"\n",
    "        connection_url = URL.create(\"mssql+pyodbc\", query={\"odbc_connect\": connection_string})\n",
    "        engine = create_engine(connection_url)\n",
    "    # else return None\n",
    "    else:\n",
    "        engine = None\n",
    "    # connection file to use in pd.read_sql\n",
    "    return engine\n",
    "\n",
    "# save to pickle\n",
    "def to_pickle(data, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "    print(f'{filename} pickled')\n",
    "\n",
    "# save to pickle and feature class\n",
    "def to_pickle_fc(data, filename):\n",
    "    data.spatial.to_featureclass(filename)\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "    print(f'{filename} pickled and saved as feature class')\n",
    "\n",
    "# get a pickled file as a dataframe\n",
    "def from_pickle(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    print(f'{filename} unpickled')\n",
    "    return data\n",
    "def get_commercial_zones(df):\n",
    "    columns_to_keep = ['Zoning_ID', 'Category', 'Density']\n",
    "    # filter Use_Type to Multiple Family Dwelling\n",
    "    df = df.loc[df['Category'] == 'Commercial']\n",
    "    return df[columns_to_keep]\n",
    "\n",
    "def get_tourist_zones(df):\n",
    "    columns_to_keep = ['Zoning_ID', 'Category', 'Density']\n",
    "    # filter Use_Type to Multiple Family Dwelling\n",
    "    df = df.loc[df['Category'] == 'Tourist Accommodation']\n",
    "    return df[columns_to_keep]\n",
    "\n",
    "# function to get where Zoningin_ID Use_Type = Multi-Family and Density\n",
    "def get_mf_zones(df):\n",
    "    columns_to_keep = ['Zoning_ID', 'Use_Type', 'Density']\n",
    "    # filter Use_Type to Multiple Family Dwelling\n",
    "    df = df.loc[df['Use_Type'] == 'Multiple Family Dwelling']\n",
    "    return df[columns_to_keep]\n",
    "\n",
    "# function to get where Zoningin_ID Use_Type = Multi-Family and Density\n",
    "def get_sf_zones(df):\n",
    "    columns_to_keep = ['Zoning_ID', 'Use_Type', 'Density']\n",
    "    # filter Use_Type to Multiple Family Dwelling\n",
    "    df = df.loc[df['Use_Type'] == 'Single Family Dwelling']\n",
    "    return df[columns_to_keep]\n",
    "\n",
    "def get_mf_only_zones(df):\n",
    "    columns_to_keep = ['Zoning_ID', 'Use_Type', 'Density']\n",
    "    # filter Use_Type to Single Family Dwelling and not Multiple Family Dwelling\n",
    "    dfMF = get_mf_zones(df)\n",
    "    dfSF = get_sf_zones(df)\n",
    "    # get Zoning_ID that are in both dataframes\n",
    "    df = dfMF.loc[~dfMF['Zoning_ID'].isin(dfSF['Zoning_ID'])]\n",
    "    return df[columns_to_keep]\n",
    "\n",
    "def get_sf_only_zones(df):\n",
    "    columns_to_keep = ['Zoning_ID', 'Use_Type', 'Density']\n",
    "    # filter Use_Type to Single Family Dwelling and not Multiple Family Dwelling\n",
    "    dfMF = get_mf_zones(df)\n",
    "    dfSF = get_sf_zones(df)\n",
    "    df = dfSF.loc[~dfSF['Zoning_ID'].isin(dfMF['Zoning_ID'])]\n",
    "    return df[columns_to_keep]\n",
    "\n",
    "def get_sf_mf_zones(df):\n",
    "    columns_to_keep = ['Zoning_ID', 'Use_Type', 'Density']\n",
    "    # get SF and MF zones\n",
    "    dfSF = get_sf_zones(df)\n",
    "    dfMF = get_mf_zones(df)\n",
    "    # add the two dataframes together\n",
    "    df = pd.concat([dfSF, dfMF])\n",
    "    # only keep duplicate Zoning_ID\n",
    "    df = df[df.duplicated(subset=['Zoning_ID'], keep=False)]\n",
    "    return df[columns_to_keep]\n",
    "\n",
    "def get_recieving_zones(df):\n",
    "    columns_to_keep = ['Zoning_ID', 'SPECIAL_DESIGNATION']\n",
    "    # filter transfer recieving\n",
    "    df = df.loc[df['SPECIAL_DESIGNATION'] == 'Receive']\n",
    "    return df[columns_to_keep]\n",
    "\n",
    "def get_sending_zones(df):\n",
    "    columns_to_keep = ['Zoning_ID', 'SPECIAL_DESIGNATION']\n",
    "    df = df.loc[df['SPECIAL_DESIGNATION'] == 'Transfer']\n",
    "    return df[columns_to_keep]\n",
    "\n",
    "def forecast_residential_units(df, condition, target_sum, reason):\n",
    "    # filter to parcels available for development\n",
    "    sdfAvailable = df.loc[eval(condition)]\n",
    "    running_sum = 0\n",
    "    rows_to_fill = []\n",
    "    # Loop through the rows and fill the 'new_column'\n",
    "    for idx, row in sdfAvailable.iterrows():\n",
    "        # Calculate the remaining amount that can be filled\n",
    "        remaining_amount = target_sum - running_sum\n",
    "        if row['MAX_UNITS'] <= remaining_amount:\n",
    "            # If the current row's value fits, add it to the column\n",
    "            df.loc[idx, 'FORECASTED_RESIDENTIAL_UNITS'] = row['MAX_UNITS']\n",
    "            running_sum += row['MAX_UNITS']\n",
    "            if row['MAX_UNITS'] > 0:\n",
    "                rows_to_fill.append(idx)\n",
    "        elif remaining_amount > 0:\n",
    "            # If it exceeds the remaining amount, fill with the remaining value\n",
    "            df.loc[idx, 'FORECASTED_RESIDENTIAL_UNITS'] = remaining_amount\n",
    "            running_sum += remaining_amount\n",
    "            if row['MAX_UNITS'] > 0:\n",
    "                rows_to_fill.append(idx)\n",
    "            break\n",
    "        else:\n",
    "            break\n",
    "    # reason for development\n",
    "    df.loc[rows_to_fill, 'FORECAST_REASON'] = reason\n",
    "    df_summary = pd.DataFrame({'Reason': [reason], 'Parcels_Available':[len(sdfAvailable)], 'Parcels_Used':[len(rows_to_fill)],\n",
    "                                'Total_Forecasted_Units': [running_sum], 'Total_Remaining_Units': [target_sum - running_sum]})   \n",
    "    return df, df_summary  \n",
    "\n",
    "def forecast_residential_units_infill(df, condition, target_sum, reason):\n",
    "    # filter to parcels available for development\n",
    "    sdfAvailable = df.loc[eval(condition)]\n",
    "    running_sum = 0\n",
    "    rows_to_fill = []\n",
    "    # Loop through the rows and fill the 'new_column'\n",
    "    for idx, row in sdfAvailable.iterrows():\n",
    "        # Calculate the remaining amount that can be filled\n",
    "        remaining_amount = target_sum - running_sum\n",
    "        if row['POTENTIAL_UNITS'] <= remaining_amount:\n",
    "            # If the current row's value fits, add it to the column\n",
    "            df.loc[idx, 'FORECASTED_RESIDENTIAL_UNITS'] = row['POTENTIAL_UNITS']\n",
    "            running_sum += row['POTENTIAL_UNITS']\n",
    "            if row['POTENTIAL_UNITS'] > 0:\n",
    "                rows_to_fill.append(idx)\n",
    "        elif remaining_amount > 0:\n",
    "            # If it exceeds the remaining amount, fill with the remaining value\n",
    "            df.loc[idx, 'FORECASTED_RESIDENTIAL_UNITS'] = remaining_amount\n",
    "            running_sum += remaining_amount\n",
    "            if row['POTENTIAL_UNITS'] > 0:\n",
    "                rows_to_fill.append(idx)\n",
    "            break\n",
    "        else:\n",
    "            break\n",
    "    # reason for development\n",
    "    df.loc[rows_to_fill, 'FORECAST_REASON'] = reason\n",
    "    df_summary = pd.DataFrame({'Reason': [reason], 'Parcels_Available':[len(sdfAvailable)], 'Parcels_Used':[len(rows_to_fill)],\n",
    "                                'Total_Forecasted_Units': [running_sum], 'Total_Remaining_Units': [target_sum - running_sum]})   \n",
    "    return df, df_summary\n",
    "\n",
    "def get_target_sum(df, Jurisdiction, Unit_Pool, zoning_type):\n",
    "    if zoning_type == 'MF':\n",
    "        return df.loc[(df['Jurisdiction'] == Jurisdiction) & (df['Unit_Pool'] == Unit_Pool), 'Future_Units_Adjusted_MF'].values[0]\n",
    "    elif zoning_type == 'SF':\n",
    "        return df.loc[(df['Jurisdiction'] == Jurisdiction) & (df['Unit_Pool'] == Unit_Pool), 'Future_Units_Adjusted_SF'].values[0]\n",
    "    elif zoning_type == 'Infill':\n",
    "        return df.loc[(df['Jurisdiction'] == Jurisdiction) & (df['Unit_Pool'] == Unit_Pool), 'Future_Units_Adjusted_Infill'].values[0]\n",
    "    return df.loc[(df['Jurisdiction'] == Jurisdiction) & (df['Unit_Pool'] == Unit_Pool), 'Future_Units_Adjusted'].values[0]\n",
    "\n",
    "# funtion to adust the forecasted residential units vs the target sum in the unit pool\n",
    "def adjust_pools(df, dfPool):\n",
    "    dfPool_Deductions = df.groupby(['JURISDICTION','FORECAST_REASON'])['FORECASTED_RESIDENTIAL_UNITS'].sum()\n",
    "    dfPool_Deductions = dfPool_Deductions.reset_index()\n",
    "    # unit pool field\n",
    "    dfPool_Deductions['Unit_Pool'] = 'NA'\n",
    "    # set unit pool to Juirsidiction + Forecast Reason\n",
    "    dfPool_Deductions['Unit_Pool'] = dfPool_Deductions['JURISDICTION'] + ' ' + dfPool_Deductions['FORECAST_REASON']\n",
    "    # merge the two dataframes\n",
    "    dfPool = pd.merge(dfPool, dfPool_Deductions, on='Unit_Pool', how='left')\n",
    "    # fill NaN with 0\n",
    "    dfPool['FORECASTED_RESIDENTIAL_UNITS'] = dfPool['FORECASTED_RESIDENTIAL_UNITS'].fillna(0)\n",
    "    # adjust the forecasted units\n",
    "    dfPool['Future_Units_Adjusted']    = dfPool['Future_Units_Adjusted'] - dfPool['FORECASTED_RESIDENTIAL_UNITS']\n",
    "    # adjust the forecasted units\n",
    "    dfPool['Future_Units_Adjusted_MF'] = dfPool['Future_Units_Adjusted_MF'] - dfPool['FORECASTED_RESIDENTIAL_UNITS']\n",
    "    # adjust the forecasted units\n",
    "    dfPool['Future_Units_Adjusted_SF'] = dfPool['Future_Units_Adjusted_SF'] - dfPool['FORECASTED_RESIDENTIAL_UNITS']\n",
    "    # adjust the forecasted units\n",
    "    dfPool['Future_Units_Adjusted_Infill'] = dfPool['Future_Units_Adjusted_Infill'] - dfPool['FORECASTED_RESIDENTIAL_UNITS']\n",
    "    # return the dataframe\n",
    "    return dfPool_Deductions, dfPool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parcel development layer polygons\n",
    "parcel_db = Path(sdeEdit) / \"SDE.Parcel\\\\SDE.Parcel_History_Attributed\"\n",
    "# query 2022 rows\n",
    "sdf_units = pd.DataFrame.spatial.from_featureclass(parcel_db)\n",
    "sdf_units = sdf_units.loc[sdf_units['YEAR'] == 2022]\n",
    "sdf_units.spatial.sr = sr\n",
    "\n",
    "# # get parcel level data from Collection SDE\n",
    "# vhr feature layer polygons \n",
    "vhr_db = Path(sdeCollect) / \"SDE.Parcel\\\\SDE.Parcel_VHR\"\n",
    "sdf_vhr = pd.DataFrame.spatial.from_featureclass(vhr_db)\n",
    "sdf_vhr.spatial.sr = sr\n",
    "# filter vhr layer to active status\n",
    "sdf_vhr = sdf_vhr.loc[sdf_vhr['Status'] == 'Active']\n",
    "\n",
    "# TAZ feature layer polygons\n",
    "taz_db = Path(sdeBase) / \"SDE.Transportation\\\\SDE.Transportation_Analysis_Zone\"\n",
    "# get as spatial dataframe\n",
    "sdf_taz = pd.DataFrame.spatial.from_featureclass(taz_db)\n",
    "# set spatial reference to NAD 1983 UTM Zone 10N\n",
    "sdf_taz.spatial.sr = sr\n",
    "\n",
    "# censuse feature class\n",
    "census_fc    = Path(sdeBase) / \"SDE.Census\\\\SDE.Tahoe_Census_Geography\"\n",
    "# bouns unit boundary feature class\n",
    "bonus_unit_fc = Path(sdeBase) / \"SDE.Planning\\SDE.Bonus_unit_boundary\"\n",
    "\n",
    "# disable Z values on block group feature layer\n",
    "with arcpy.EnvManager(outputZFlag=\"Disabled\"):    \n",
    "    arcpy.conversion.FeatureClassToGeodatabase(\n",
    "        Input_Features=\"F:\\GIS\\DB_CONNECT\\Vector.sde\\SDE.Census\\SDE.Tahoe_Census_Geography\",\n",
    "        Output_Geodatabase=r\"C:\\Users\\mbindl\\Desktop\\Workspace.gdb\"\n",
    "    )\n",
    "# disable Z values on block group feature layer\n",
    "with arcpy.EnvManager(outputZFlag=\"Disabled\"):    \n",
    "    arcpy.conversion.FeatureClassToGeodatabase(\n",
    "        Input_Features=\"F:\\GIS\\DB_CONNECT\\Vector.sde\\SDE.Planning\\SDE.Bonus_unit_boundary\",\n",
    "        Output_Geodatabase=r\"C:\\Users\\mbindl\\Desktop\\Workspace.gdb\"\n",
    "    )\n",
    "\n",
    "# block group feature layer polygons with no Z\n",
    "sdf_block = pd.DataFrame.spatial.from_featureclass(Path(gdb) / 'Tahoe_Census_Geography')\n",
    "sdf_block = sdf_block.loc[(sdf_block['YEAR'] == 2020) & (sdf_block['GEOGRAPHY'] == 'Block Group')]\n",
    "sdf_block.spatial.sr = sr\n",
    "\n",
    "# bonus unit boundary wihtout Z\n",
    "sdf_bonus = pd.DataFrame.spatial.from_featureclass(Path(gdb) / 'Bonus_unit_boundary')\n",
    "sdf_bonus.spatial.sr = sr\n",
    "\n",
    "# get parcel level data from LTinfo\n",
    "dfIPES       = pd.read_json(\"https://www.laketahoeinfo.org/WebServices/GetParcelIPESScores/JSON/e17aeb86-85e3-4260-83fd-a2b32501c476\")\n",
    "dfLCV_LTinfo = pd.read_json('https://www.laketahoeinfo.org/WebServices/GetParcelsByLandCapability/JSON/e17aeb86-85e3-4260-83fd-a2b32501c476')\n",
    "dfRetired    = pd.read_json(\"https://www.laketahoeinfo.org/WebServices/GetAllParcels/JSON/e17aeb86-85e3-4260-83fd-a2b32501c476\")\n",
    "dfBankedDev  = pd.read_json('https://www.laketahoeinfo.org/WebServices/GetBankedDevelopmentRights/JSON/e17aeb86-85e3-4260-83fd-a2b32501c476')\n",
    "dfTransacted = pd.read_json('https://www.laketahoeinfo.org/WebServices/GetTransactedAndBankedDevelopmentRights/JSON/e17aeb86-85e3-4260-83fd-a2b32501c476')\n",
    "dfAllParcels = pd.read_json('https://www.laketahoeinfo.org/WebServices/GetAllParcels/JSON/e17aeb86-85e3-4260-83fd-a2b32501c476')\n",
    "\n",
    "# get use tables \n",
    "# zoning data\n",
    "sde_engine = get_conn('sde')\n",
    "with sde_engine.begin() as conn:\n",
    "    df_uses    = pd.read_sql(\"SELECT * FROM sde.SDE.PermissibleUses\", conn)\n",
    "    df_special = pd.read_sql(\"SELECT * FROM sde.SDE.Special_Designation\", conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parcel Data Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spatial join to get TAZ\n",
    "arcpy.SpatialJoin_analysis(sdf_units, sdf_taz, \"Existing_Development_TAZ\", \n",
    "                           \"JOIN_ONE_TO_ONE\", \"KEEP_ALL\", \"\", \"HAVE_THEIR_CENTER_IN\")\n",
    "# spatial join to get Block Group\n",
    "arcpy.SpatialJoin_analysis(sdf_units, sdf_block, \"Existing_Development_BlockGroup\", \n",
    "                           \"JOIN_ONE_TO_ONE\", \"KEEP_ALL\", \"\", \"HAVE_THEIR_CENTER_IN\")\n",
    "# spatial join of Bonus Unit Boundary\n",
    "arcpy.SpatialJoin_analysis(sdf_units, sdf_bonus, \"Existing_Development_BonusUnitBoundary\",\n",
    "                            \"JOIN_ONE_TO_ONE\", \"KEEP_ALL\", \"\", \"INTERSECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spatial dataframe with only initial columns\n",
    "sdfParcels = sdf_units[initial_columns]\n",
    "\n",
    "# get results of spatial joins as spatial dataframes\n",
    "sdf_units_taz   = pd.DataFrame.spatial.from_featureclass(\"Existing_Development_TAZ\", sr=sr)  \n",
    "sdf_units_block = pd.DataFrame.spatial.from_featureclass(\"Existing_Development_BlockGroup\", sr=sr)\n",
    "sdf_units_bonus = pd.DataFrame.spatial.from_featureclass(\"Existing_Development_BonusUnitBoundary\", sr=sr)\n",
    "# cast to string\n",
    "sdf_units_bonus['WITHIN_BONUSUNIT_BNDY'] = sdf_units_bonus['WITHIN_BONUSUNIT_BNDY'].astype(str)\n",
    "sdf_units_bonus['WITHIN_BONUSUNIT_BNDY'] = 'No'\n",
    "# if Id is not NA then within bonus unit boundary = yes, else\n",
    "sdf_units_bonus.loc[sdf_units_bonus['Id'].notna(), 'WITHIN_BONUSUNIT_BNDY'] = 'Yes'\n",
    "\n",
    "# map dictionary to sdf_units dataframe to fill in TAZ and Block Group fields\n",
    "sdfParcels['TAZ']                   = sdfParcels.APN.map(dict(zip(sdf_units_taz.APN,   sdf_units_taz.TAZ_1)))\n",
    "sdfParcels['BLOCK_GROUP']           = sdfParcels.APN.map(dict(zip(sdf_units_block.APN, sdf_units_block.TRPAID)))\n",
    "# map IPES score to parcels\n",
    "sdfParcels['IPES_SCORE']            = sdfParcels['APN'].map(dict(zip(dfIPES.APN, dfIPES.IPESScore)))\n",
    "sdfParcels['IPES_SCORE_TYPE']       = sdfParcels['APN'].map(dict(zip(dfIPES.APN, dfIPES.IPESScoreType)))\n",
    "# retired parcels\n",
    "sdfParcels['RETIRED']               = sdfParcels['APN'].map(dict(zip(dfAllParcels.APN, dfAllParcels.RetiredFromDevelopment)))\n",
    "sdfParcels['WITHIN_BONUSUNIT_BNDY'] = sdfParcels['APN'].map(dict(zip(sdf_units_bonus.APN, sdf_units_bonus.WITHIN_BONUSUNIT_BNDY)))\n",
    "# define housnig zoning and density\n",
    "sdfParcels['HOUSING_ZONING']          = 'NA'\n",
    "sdfParcels['COMMERCIAL_ALLOWED']      = 'No'\n",
    "sdfParcels['TOURIST_ALLOWED']         = 'No'\n",
    "\n",
    "# if the zoning id is in the list of multiple family zones then set to MF\n",
    "sdfParcels.loc[sdfParcels['ZONING_ID'].isin(get_sf_mf_zones(df_uses)['Zoning_ID']), 'HOUSING_ZONING'] = 'SF/MF'\n",
    "# if the zoning id is in the list of single family zones and not in the multiple family zones then set to SF only\n",
    "sdfParcels.loc[sdfParcels['ZONING_ID'].isin(get_sf_only_zones(df_uses)['Zoning_ID']), 'HOUSING_ZONING'] = 'SF_only'\n",
    "# if the zoning id is in the list of multiple family zones and not in the single family zones then set to MF only\n",
    "sdfParcels.loc[sdfParcels['ZONING_ID'].isin(get_mf_only_zones(df_uses)['Zoning_ID']), 'HOUSING_ZONING'] = 'MF_only'\n",
    "# if the zoning id is in the list of commercial zones then set to Commercial\n",
    "sdfParcels.loc[sdfParcels['ZONING_ID'].isin(get_commercial_zones(df_uses)['Zoning_ID']), 'COMMERCIAL_ALLOWED'] = 'Yes'\n",
    "# if the zoning id is in the list of tourist zones then set to Tourist Accommodation\n",
    "sdfParcels.loc[sdfParcels['ZONING_ID'].isin(get_tourist_zones(df_uses)['Zoning_ID']), 'TOURIST_ALLOWED'] = 'Yes'\n",
    "\n",
    "# if COUNTY is in EL or PL and SF allowed then set ADU_ALLOWED to yes or if COUNTY is in WA, DG, or CC and parcel acres is greater than 1 and SF allowed then set ADU_ALLOWED to yes\n",
    "sdfParcels['ADU_ALLOWED'] = 'No'\n",
    "sdfParcels.loc[(sdfParcels['COUNTY'].isin(['EL','PL'])) & (~sdfParcels['HOUSING_ZONING'].isin(['MF_only', 'NA'])), 'ADU_ALLOWED'] = 'Yes'\n",
    "sdfParcels.loc[(sdfParcels['COUNTY'].isin(['WA','DG','CC'])) & (sdfParcels['PARCEL_ACRES']>=1) &(~sdfParcels['HOUSING_ZONING'].isin(['MF_only', 'NA'])), 'ADU_ALLOWED'] = 'Yes'\n",
    "\n",
    "# get density for MF and MF only zones, max residential units, and adjusted residential units\n",
    "dfMF = get_mf_zones(df_uses)\n",
    "sdfParcels['DENSITY']                    = sdfParcels['ZONING_ID'].map(dict(zip(dfMF.Zoning_ID, dfMF.Density)))\n",
    "sdfParcels['MAX_RESIDENTIAL_UNITS']      = sdfParcels['PARCEL_ACRES'] * sdfParcels['DENSITY']\n",
    "sdfParcels['MAX_UNITS']                  = sdfParcels['MAX_RESIDENTIAL_UNITS']*0.6\n",
    "sdfParcels['MAX_UNITS']                  = sdfParcels['MAX_UNITS'].fillna(0).astype(int)\n",
    "\n",
    "# set SF only zones to 1 max unit\n",
    "sdfParcels.loc[sdfParcels['HOUSING_ZONING'] == 'SF_only', 'MAX_UNITS'] = 1\n",
    "\n",
    "# set field for underbuilt evaluation\n",
    "sdfParcels['POTENTIAL_UNITS'] = 0\n",
    "sdfParcels['POTENTIAL_UNITS'] = sdfParcels['MAX_UNITS'] - sdfParcels['Residential_Units']\n",
    "# calculate parcels with the greatest buildable potential  filter to the top 10% of parcels\n",
    "# what value is in the top 10% of the potential buildable units\n",
    "top_10_threshold = sdfParcels.POTENTIAL_UNITS.quantile(0.9)\n",
    "# filter out rows where POTENTIAL_BUILDABLE_UNITS is NaN\n",
    "sdfParcels['TOP_TEN_POTENTIAL_UNITS'] = sdfParcels.apply(lambda x: 'Yes' if x['POTENTIAL_UNITS'] >= top_10_threshold else 'No', axis=1)\n",
    "\n",
    "# set FORECASTED_RESIDENTIAL_UNITS to 0\n",
    "sdfParcels['FORECASTED_RESIDENTIAL_UNITS']     = 0\n",
    "# set FORECAST_COMMERCIAN_UNITS to 0\n",
    "sdfParcels['FORECASTED_COMMERCIAL_SQFT']       = 0\n",
    "# set FORECAST_TOURIST_UNITS to 0\n",
    "sdfParcels['FORECASTED_TOURIST_UNITS']         = 0\n",
    "# set FORECAST_REASON to na\n",
    "sdfParcels['FORECAST_REASON']                  = None\n",
    "# FORECASTED_OCCUPANCY_RATE as a float field\n",
    "sdfParcels['FORECASTED_RES_OCCUPANCY_RATE']    = 0.0\n",
    "\n",
    "# export to pickle\n",
    "sdfParcels.to_pickle(parcel_pickle_part1)\n",
    "# to feature class\n",
    "sdfParcels.spatial.to_featureclass(Path(gdb)/'Parcel_Base_2022')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Year Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residential Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Assign Known Projects\n",
    "* Assign using Lookup_Lists\\forecast_residential_assigned_units.csv: \n",
    "    * Known Residential Allocations from 2023-2024, \n",
    "    * Known Residential Bonus Units from permitted projects, \n",
    "    * applications in review, and \n",
    "    * RBU reservations in LT Info\n",
    "    * Known Accessory Dwelling permits not completed\n",
    "    * Remove Known Banking projects that removed units in 2023-2024\n",
    "* Calcuate Remaining local jurisdiction pool units less units used for known projects\n",
    "    \n",
    "2) Assign Residential Bonus Units within Bonus Unit Boundary\n",
    "* Full build out of CTC Asset Lands using jurisdiction bonus unit pools\n",
    "* Identify vacant buildable lots within Bonus Unit boundary\n",
    "* Assign remaining jurisdiction pool units to available parcels within jurisidiction\n",
    "\n",
    "3) Assigne remaining Jurisdiction Residential Bonus and General Units\n",
    "* Identify\tVacant buildable lots with allowed Multi-family use, calculate allowed density\n",
    "* Assign 15% of remaining local jurisdiction Residential Allocation pool units to available multi-family parcels within jurisidiction\n",
    "* Assign 35% of remaining Banked units to available multi-family parcels (use adjusted weighting from existing residential units?)\n",
    "* Assign 35% of remaining Converted units to available multi-family parcels (use adjusted weighting from existing residential units?)\n",
    "    \n",
    "4) Assign remaining TRPA pool units to available parcels throughout region (use adjusted weighting from existing residential units?)\n",
    "* Evaluate Vacant Buildable Lots with Single-family Residential Allowed Use\t\n",
    "* Identify\tVacant buildable lots with allowed Single-family use\n",
    "* Identify\tAccessory Dwelling Uses Allowed (All California Parcels and NV Parcels Greater than 1 Acre)\n",
    "* Evaluate Underbuilt parcels with Multi-family Residential Allowed Use\t\n",
    "* Identify\tUnderbuilt Residential lots with allowed Multi-family use\n",
    "* Evaluate Underbuilt parcels with Accessory Dwelling Uses Allowed (All California Parcels and NV Parcels Greater than 1 Acre)\t\n",
    "* Identify parcels that are in Town Centers or within a quarter mile and are top x% of underbuilt parcels. \n",
    "* Underbuilt = exclude existing condo and common area land uses. sf mf or mixed use\n",
    "* ADU potential = exclude existing condo or common area land uses, and wait to use any NV parcels>acre. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Get the Parcel Base Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mbindl\\Documents\\GitHub\\Transportation\\RegionalTransportationPlan\\2023\\data\\parcel_pickle1.pkl unpickled\n"
     ]
    }
   ],
   "source": [
    "# get pickle 1 as a spatially enabled dataframe - spatial joins, foreign keys, and new categorical fields added already\n",
    "sdfParcels = from_pickle(parcel_pickle_part1)\n",
    "# Randomly sort parcels so that development can be assigned randomly\n",
    "sdfParcels = sdfParcels.sample(frac=1).reset_index(drop=True)\n",
    "# Export index and apn to a csv file for future reference with a name that includes the date and time\n",
    "# This will allow us to recreate the same random order in the future\n",
    "sdfParcels[['APN']].to_csv(f\"Parcel_Sort_Order_{pd.Timestamp.now().strftime('%Y%m%d%H%M%S')}.csv\", index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Get Lookup Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to lookup lists\n",
    "res_assigned_lookup = \"Lookup_Lists/forecast_residential_assigned_units.csv\"\n",
    "res_zoned_lookup    = \"Lookup_Lists/forecast_residential_zoned_units.csv\"\n",
    "ctc_assetlands_lookup = \"Lookup_Lists/CTC_AssetLands_Lookup.csv\"\n",
    "\n",
    "# get zoned and assigned lookup lists as data frames\n",
    "dfResZoned    = pd.read_csv(res_zoned_lookup)\n",
    "dfResAssigned = pd.read_csv(res_assigned_lookup)\n",
    "# get lookup list for CTC asset lands (17 parcels)\n",
    "ctc_parcels = pd.read_csv(ctc_assetlands_lookup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Assign Known Projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast Known Residential Projects from 2023-2024\n",
    "# group dfResAssigned by APN and sum Unit Change to aggregate to one total for duplciate \n",
    "dfResAssignedGrouped_APN = dfResAssigned.groupby('APN').sum('Unit Change').reset_index()\n",
    "# assign forecast residential units for assigned projects\n",
    "sdfParcels['FORECASTED_RESIDENTIAL_UNITS'] = sdfParcels.APN.map(dict(zip(dfResAssignedGrouped_APN.APN, dfResAssignedGrouped_APN['Unit Change'])))\n",
    "# forecast reason = Assigned for APNs in dfResAssignedGrouped\n",
    "sdfParcels.loc[sdfParcels['APN'].isin(dfResAssigned['APN']), 'FORECAST_REASON'] = 'Assigned'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JURISDICTION  FORECAST_REASON\n",
       "CSLT          Assigned           528.0\n",
       "DG            Assigned           151.0\n",
       "EL            Assigned            10.0\n",
       "PL            Assigned           402.0\n",
       "WA            Assigned            71.0\n",
       "Name: FORECASTED_RESIDENTIAL_UNITS, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdfParcels.groupby(['JURISDICTION','FORECAST_REASON'])['FORECASTED_RESIDENTIAL_UNITS'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Forecasted Units: 1216.0\n"
     ]
    }
   ],
   "source": [
    "# total forecasted units\n",
    "total_forecasted_units = sdfParcels['FORECASTED_RESIDENTIAL_UNITS'].sum()\n",
    "print(f'Total Forecasted Units: {total_forecasted_units}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Forecast full buildout of CTC Asset Lands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CTC Asset Lands ##\n",
    "# set the forecast reason to CTC Asset Lands for the 17 parcels n\n",
    "sdfParcels.loc[(sdfParcels['APN'].isin(ctc_parcels['APN'])) & (sdfParcels['FORECAST_REASON']!='Assigned'), 'FORECAST_REASON'] = 'CTC Asset Lands'\n",
    "# CTC asset lands that are truly buildable\n",
    "CTC_condition          = \"(sdfParcels['FORECAST_REASON'] == 'CTC Asset Lands') & (sdfParcels['POTENTIAL_UNITS'] > 0) & (sdfParcels['TOP_TEN_POTENTIAL_UNITS'] == 'Yes')\"\n",
    "# assign POTEINTIAL_UNITS to FORECASTED_RESIDENTIAL_UNITS for CTC Asset Lands that are buildable and not built by 2024\n",
    "sdfParcels.loc[eval(CTC_condition), 'FORECASTED_RESIDENTIAL_UNITS'] = sdfParcels['POTENTIAL_UNITS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JURISDICTION  FORECAST_REASON\n",
       "CSLT          Assigned           528.0\n",
       "              CTC Asset Lands     15.0\n",
       "DG            Assigned           151.0\n",
       "EL            Assigned            10.0\n",
       "              CTC Asset Lands     26.0\n",
       "PL            Assigned           402.0\n",
       "              CTC Asset Lands     13.0\n",
       "WA            Assigned            71.0\n",
       "Name: FORECASTED_RESIDENTIAL_UNITS, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdfParcels.groupby(['JURISDICTION','FORECAST_REASON'])['FORECASTED_RESIDENTIAL_UNITS'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Subtract Assigned Units from the appropriate pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subtract Assigned units from the appropriate pool\n",
    "# group dfResAssigned by Jurisdiction and Unit_Pool\n",
    "dfGroup_Assigned = dfResAssigned.groupby(['Jurisdiction', 'Unit_Pool']).sum('Unit Change').reset_index()\n",
    "# drop Occupancy_Rate and Year columns\n",
    "dfGroup_Assigned = dfGroup_Assigned.drop(columns=['Occupancy_Rate'])\n",
    "# rename Unit Change to Unit_Change\n",
    "dfGroup_Assigned = dfGroup_Assigned.rename(columns={'Unit Change':'Unit_Change'})\n",
    "\n",
    "# merge dfResAssignedGrouped with dfResZoned on Jurisdiction and Pool\n",
    "dfPool_Assigned = pd.merge(dfResZoned, dfGroup_Assigned, on=['Jurisdiction', 'Unit_Pool'], how='left')\n",
    "\n",
    "# fill NaN with 0\n",
    "dfPool_Assigned['Unit_Change'] = dfPool_Assigned['Unit_Change'].fillna(0)\n",
    "# subtract known project aggregations from the zoned unit pools\n",
    "dfPool_Assigned['Future_Units_Adjusted'] = dfPool_Assigned['Future_Units'] - dfPool_Assigned['Unit_Change']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Future_Units: 4385\n",
      "Future_Units_Adjusted: 3162.0\n",
      "Unit_Change: 1223.0\n"
     ]
    }
   ],
   "source": [
    "# sum of forecasted units, forecasted units adjusted, and unit change\n",
    "for i in ['Future_Units', 'Future_Units_Adjusted', 'Unit_Change']:\n",
    "    print(f\"{i}: {dfPool_Assigned[i].sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Subtract the CTC asset lands buildout from the appropriate pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter to CTC Asset Lands parcels \n",
    "sdfCTC = sdfParcels.loc[sdfParcels['FORECAST_REASON'] == 'CTC Asset Lands']\n",
    "# sum of forecasted residential units where forecast reason = ctc asset lands\n",
    "sdfCTC_ForecastedByJurisdiction = sdfCTC.groupby('JURISDICTION')['FORECASTED_RESIDENTIAL_UNITS'].sum().reset_index()\n",
    "# set unit pool to Bonus Unit or General based on Jurisdiction\n",
    "sdfCTC_ForecastedByJurisdiction.loc[(sdfCTC_ForecastedByJurisdiction['JURISDICTION']=='CSLT'), 'Unit_Pool'] = 'General'\n",
    "sdfCTC_ForecastedByJurisdiction.loc[(sdfCTC_ForecastedByJurisdiction['JURISDICTION']=='PL'), 'Unit_Pool']   = 'Bonus Unit'\n",
    "sdfCTC_ForecastedByJurisdiction.loc[(sdfCTC_ForecastedByJurisdiction['JURISDICTION']=='EL'), 'Unit_Pool']   = 'General'\n",
    "# rename columns\n",
    "sdfCTC_ForecastedByJurisdiction.rename(columns={'JURISDICTION': 'Jurisdiction', 'FORECASTED_RESIDENTIAL_UNITS': 'Forecasted_CTC'}, inplace=True)\n",
    "\n",
    "# Subtract CTC asset lands from the appropriate pool\n",
    "dfPool_CTC = sdfCTC_ForecastedByJurisdiction.copy()\n",
    "# merge with dfResMerge\n",
    "dfPool_CTC = pd.merge(dfPool_Assigned, dfPool_CTC, on=['Jurisdiction', 'Unit_Pool'], how='left')\n",
    "\n",
    "# fill NaN with 0\n",
    "dfPool_CTC['Forecasted_CTC'] = dfPool_CTC['Forecasted_CTC'].fillna(0)\n",
    "# subtract CTC asset lands from the appropriate pool\n",
    "dfPool_CTC['Future_Units_Adjusted'] = dfPool_CTC['Future_Units_Adjusted'] - dfPool_CTC['Forecasted_CTC']\n",
    "# add CTC Max Build to the unit change\n",
    "dfPool_CTC['Unit_Change'] = dfPool_CTC['Unit_Change'] + dfPool_CTC['Forecasted_CTC']\n",
    "# drop CTC Built column\n",
    "dfPool_CTC.drop(columns=['Forecasted_CTC'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Future_Units: 4385\n",
      "Future_Units_Adjusted: 3108.0\n",
      "Unit_Change: 1277.0\n"
     ]
    }
   ],
   "source": [
    "# sum of forecasted units, forecasted units adjusted, and unit change\n",
    "for i in ['Future_Units', 'Future_Units_Adjusted', 'Unit_Change']:\n",
    "    print(f\"{i}: {dfPool_CTC[i].sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Setup Unit Pools Proportion to be Used in Each Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPool = dfPool_CTC.copy()\n",
    "# proportion target of forecast development by type\n",
    "portion_multifamily = .35\n",
    "portion_singlefamily = .5\n",
    "portion_infill = .15\n",
    "# Set units to use for each zoning type\n",
    "dfPool['Future_Units_Adjusted'] = dfPool['Future_Units_Adjusted'].fillna(0)\n",
    "dfPool['Future_Units_Adjusted_MF'] = (dfPool['Future_Units_Adjusted'] * portion_multifamily).round().astype(int)\n",
    "dfPool['Future_Units_Adjusted_SF'] = (dfPool['Future_Units_Adjusted'] * portion_singlefamily).round().astype(int)\n",
    "dfPool['Future_Units_Adjusted_Infill'] = (dfPool['Future_Units_Adjusted'] * portion_infill).round().astype(int)\n",
    "# Assign any rounding error to the single family pool\n",
    "dfPool['Adjustment'] = dfPool['Future_Units_Adjusted'] - dfPool['Future_Units_Adjusted_MF'] - dfPool['Future_Units_Adjusted_SF'] - dfPool['Future_Units_Adjusted_Infill']\n",
    "dfPool['Future_Units_Adjusted_SF'] = dfPool['Future_Units_Adjusted_SF'] + dfPool['Adjustment']\n",
    "dfPool.drop(columns=['Adjustment'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Jurisdiction</th>\n",
       "      <th>Unit_Pool</th>\n",
       "      <th>Future_Units</th>\n",
       "      <th>Unit_Change</th>\n",
       "      <th>Future_Units_Adjusted</th>\n",
       "      <th>Future_Units_Adjusted_MF</th>\n",
       "      <th>Future_Units_Adjusted_SF</th>\n",
       "      <th>Future_Units_Adjusted_Infill</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CSLT</td>\n",
       "      <td>Bonus Unit</td>\n",
       "      <td>109</td>\n",
       "      <td>41.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>24</td>\n",
       "      <td>34.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CSLT</td>\n",
       "      <td>General</td>\n",
       "      <td>404</td>\n",
       "      <td>70.0</td>\n",
       "      <td>334.0</td>\n",
       "      <td>117</td>\n",
       "      <td>167.0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DG</td>\n",
       "      <td>Bonus Unit</td>\n",
       "      <td>67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>23</td>\n",
       "      <td>34.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DG</td>\n",
       "      <td>General</td>\n",
       "      <td>162</td>\n",
       "      <td>112.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>18</td>\n",
       "      <td>24.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EL</td>\n",
       "      <td>General</td>\n",
       "      <td>317</td>\n",
       "      <td>39.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>97</td>\n",
       "      <td>139.0</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PL</td>\n",
       "      <td>General</td>\n",
       "      <td>615</td>\n",
       "      <td>186.0</td>\n",
       "      <td>429.0</td>\n",
       "      <td>150</td>\n",
       "      <td>215.0</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PL</td>\n",
       "      <td>Bonus Unit</td>\n",
       "      <td>41</td>\n",
       "      <td>13.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>10</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>WA</td>\n",
       "      <td>General</td>\n",
       "      <td>189</td>\n",
       "      <td>27.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>57</td>\n",
       "      <td>81.0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>WA</td>\n",
       "      <td>Bonus Unit</td>\n",
       "      <td>120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>42</td>\n",
       "      <td>60.0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TRPA</td>\n",
       "      <td>General</td>\n",
       "      <td>1100</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>358</td>\n",
       "      <td>512.0</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TRPA</td>\n",
       "      <td>Bonus Unit</td>\n",
       "      <td>1111</td>\n",
       "      <td>687.0</td>\n",
       "      <td>424.0</td>\n",
       "      <td>148</td>\n",
       "      <td>212.0</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TRPA</td>\n",
       "      <td>ADU</td>\n",
       "      <td>150</td>\n",
       "      <td>26.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>43</td>\n",
       "      <td>62.0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Jurisdiction   Unit_Pool  Future_Units  Unit_Change  Future_Units_Adjusted  \\\n",
       "0          CSLT  Bonus Unit           109         41.0                   68.0   \n",
       "1          CSLT     General           404         70.0                  334.0   \n",
       "2            DG  Bonus Unit            67          0.0                   67.0   \n",
       "3            DG     General           162        112.0                   50.0   \n",
       "4            EL     General           317         39.0                  278.0   \n",
       "5            PL     General           615        186.0                  429.0   \n",
       "6            PL  Bonus Unit            41         13.0                   28.0   \n",
       "7            WA     General           189         27.0                  162.0   \n",
       "8            WA  Bonus Unit           120          0.0                  120.0   \n",
       "9          TRPA     General          1100         76.0                 1024.0   \n",
       "10         TRPA  Bonus Unit          1111        687.0                  424.0   \n",
       "11         TRPA         ADU           150         26.0                  124.0   \n",
       "\n",
       "    Future_Units_Adjusted_MF  Future_Units_Adjusted_SF  \\\n",
       "0                         24                      34.0   \n",
       "1                        117                     167.0   \n",
       "2                         23                      34.0   \n",
       "3                         18                      24.0   \n",
       "4                         97                     139.0   \n",
       "5                        150                     215.0   \n",
       "6                         10                      14.0   \n",
       "7                         57                      81.0   \n",
       "8                         42                      60.0   \n",
       "9                        358                     512.0   \n",
       "10                       148                     212.0   \n",
       "11                        43                      62.0   \n",
       "\n",
       "    Future_Units_Adjusted_Infill  \n",
       "0                             10  \n",
       "1                             50  \n",
       "2                             10  \n",
       "3                              8  \n",
       "4                             42  \n",
       "5                             64  \n",
       "6                              4  \n",
       "7                             24  \n",
       "8                             18  \n",
       "9                            154  \n",
       "10                            64  \n",
       "11                            19  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfPool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Define Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "##------------------------------------ Conditional Statements for Forecasting Residential Unit Development------------------------------ ##\n",
    "# vacant buildable criteria\n",
    "vacant_buildable_criteria        = \"(df['FORECAST_REASON'].isna()) & (df['EXISTING_LANDUSE'] == 'Vacant') & (df['OWNERSHIP_TYPE'] == 'Private') & (df['RETIRED'] == 'No') & (df['IPES_SCORE'] > 0)\"\n",
    "placer_vacant_buildable_criteria = \"(df['FORECAST_REASON'].isna()) & (df['EXISTING_LANDUSE'] == 'Vacant') & (df['OWNERSHIP_TYPE'] == 'Private') & (df['RETIRED'] == 'No') & (df['IPES_SCORE'] > 726)\" \n",
    "# Within TRPA Boundary as condition for all\n",
    "trpa_boundary_criteria = \"(df['WITHIN_TRPA_BNDY'] == 1)\"\n",
    "no_zoning_criteria     = \"(df['HOUSING_ZONING'] != 'NA')\"\n",
    "sf_only_criteria       = \"(df['HOUSING_ZONING'] == 'SF_only')\"\n",
    "mf_only_criteria       = \"(df['HOUSING_ZONING'] == 'MF_only')\"\n",
    "sf_mf_criteria         = \"(df['HOUSING_ZONING'].isin(['SF/MF', 'MF_only']))\"\n",
    "bonus_criteria         = \"(df['WITHIN_BONUSUNIT_BNDY'] == 'Yes')\"\n",
    "adu_criteria           = \"(df['ADU_ALLOWED'] == 'Yes')\"\n",
    "towncenter_condition   = \"(~df['TOWN_CENTER'].isna())\"\n",
    "tc_quarter_condition   = \"(df['LOCATION_TO_TOWNCENTER'] == 'Within 1/4 Mile')\"\n",
    "top_10_condition       = \"(df['TOP_TEN_POTENTIAL_UNITS'] == 'Yes')\"\n",
    "parcel_size_condition  = \"(df['PARCEL_ACRES'] >= 0.15)\"\n",
    "condo_condition        = \"(~df['EXISTING_LANDUSE'].isin('Condominium', 'Condomunium Common Area'))\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Forecast Jurisdiction Pools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Jurisdiction</th>\n",
       "      <th>Unit_Pool</th>\n",
       "      <th>Future_Units</th>\n",
       "      <th>Unit_Change</th>\n",
       "      <th>Future_Units_Adjusted</th>\n",
       "      <th>Future_Units_Adjusted_MF</th>\n",
       "      <th>Future_Units_Adjusted_SF</th>\n",
       "      <th>Future_Units_Adjusted_Infill</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CSLT</td>\n",
       "      <td>Bonus Unit</td>\n",
       "      <td>109</td>\n",
       "      <td>41.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>24</td>\n",
       "      <td>34.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CSLT</td>\n",
       "      <td>General</td>\n",
       "      <td>404</td>\n",
       "      <td>70.0</td>\n",
       "      <td>334.0</td>\n",
       "      <td>117</td>\n",
       "      <td>167.0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DG</td>\n",
       "      <td>Bonus Unit</td>\n",
       "      <td>67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>23</td>\n",
       "      <td>34.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DG</td>\n",
       "      <td>General</td>\n",
       "      <td>162</td>\n",
       "      <td>112.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>18</td>\n",
       "      <td>24.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EL</td>\n",
       "      <td>General</td>\n",
       "      <td>317</td>\n",
       "      <td>39.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>97</td>\n",
       "      <td>139.0</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PL</td>\n",
       "      <td>General</td>\n",
       "      <td>615</td>\n",
       "      <td>186.0</td>\n",
       "      <td>429.0</td>\n",
       "      <td>150</td>\n",
       "      <td>215.0</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PL</td>\n",
       "      <td>Bonus Unit</td>\n",
       "      <td>41</td>\n",
       "      <td>13.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>10</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>WA</td>\n",
       "      <td>General</td>\n",
       "      <td>189</td>\n",
       "      <td>27.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>57</td>\n",
       "      <td>81.0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>WA</td>\n",
       "      <td>Bonus Unit</td>\n",
       "      <td>120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>42</td>\n",
       "      <td>60.0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TRPA</td>\n",
       "      <td>General</td>\n",
       "      <td>1100</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>358</td>\n",
       "      <td>512.0</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TRPA</td>\n",
       "      <td>Bonus Unit</td>\n",
       "      <td>1111</td>\n",
       "      <td>687.0</td>\n",
       "      <td>424.0</td>\n",
       "      <td>148</td>\n",
       "      <td>212.0</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TRPA</td>\n",
       "      <td>ADU</td>\n",
       "      <td>150</td>\n",
       "      <td>26.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>43</td>\n",
       "      <td>62.0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Jurisdiction   Unit_Pool  Future_Units  Unit_Change  Future_Units_Adjusted  \\\n",
       "0          CSLT  Bonus Unit           109         41.0                   68.0   \n",
       "1          CSLT     General           404         70.0                  334.0   \n",
       "2            DG  Bonus Unit            67          0.0                   67.0   \n",
       "3            DG     General           162        112.0                   50.0   \n",
       "4            EL     General           317         39.0                  278.0   \n",
       "5            PL     General           615        186.0                  429.0   \n",
       "6            PL  Bonus Unit            41         13.0                   28.0   \n",
       "7            WA     General           189         27.0                  162.0   \n",
       "8            WA  Bonus Unit           120          0.0                  120.0   \n",
       "9          TRPA     General          1100         76.0                 1024.0   \n",
       "10         TRPA  Bonus Unit          1111        687.0                  424.0   \n",
       "11         TRPA         ADU           150         26.0                  124.0   \n",
       "\n",
       "    Future_Units_Adjusted_MF  Future_Units_Adjusted_SF  \\\n",
       "0                         24                      34.0   \n",
       "1                        117                     167.0   \n",
       "2                         23                      34.0   \n",
       "3                         18                      24.0   \n",
       "4                         97                     139.0   \n",
       "5                        150                     215.0   \n",
       "6                         10                      14.0   \n",
       "7                         57                      81.0   \n",
       "8                         42                      60.0   \n",
       "9                        358                     512.0   \n",
       "10                       148                     212.0   \n",
       "11                        43                      62.0   \n",
       "\n",
       "    Future_Units_Adjusted_Infill  \n",
       "0                             10  \n",
       "1                             50  \n",
       "2                             10  \n",
       "3                              8  \n",
       "4                             42  \n",
       "5                             64  \n",
       "6                              4  \n",
       "7                             24  \n",
       "8                             18  \n",
       "9                            154  \n",
       "10                            64  \n",
       "11                            19  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfPool = dfPool.copy()\n",
    "dfPool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Future_Units: 4385\n",
      "Future_Units_Adjusted: 3108.0\n",
      "Unit_Change: 1277.0\n"
     ]
    }
   ],
   "source": [
    "# sum of forecasted units, forecasted units adjusted, and unit change\n",
    "for i in ['Future_Units', 'Future_Units_Adjusted', 'Unit_Change']:\n",
    "    print(f\"{i}: {dfPool[i].sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Assign Units using the Bonus Unit Pools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reason</th>\n",
       "      <th>Parcels_Available</th>\n",
       "      <th>Parcels_Used</th>\n",
       "      <th>Total_Forecasted_Units</th>\n",
       "      <th>Total_Remaining_Units</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CSLT Bonus Units MF</td>\n",
       "      <td>248</td>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CSLT Bonus Units SF</td>\n",
       "      <td>413</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CSLT Bonus Units Infill</td>\n",
       "      <td>5834</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DG Bonus Units MF</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DG Bonus Units Infill</td>\n",
       "      <td>1322</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PL Bonus Units MF</td>\n",
       "      <td>80</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PL Bonus Units SF</td>\n",
       "      <td>242</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PL Bonus Units Infill</td>\n",
       "      <td>3746</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>WA Bonus Units MF</td>\n",
       "      <td>22</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WA Bonus Units SF</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>WA Bonus Units Infill</td>\n",
       "      <td>4227</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Reason  Parcels_Available  Parcels_Used  \\\n",
       "0       CSLT Bonus Units MF                248             9   \n",
       "1       CSLT Bonus Units SF                413            34   \n",
       "2   CSLT Bonus Units Infill               5834             4   \n",
       "3         DG Bonus Units MF                  3             2   \n",
       "4     DG Bonus Units Infill               1322             7   \n",
       "5         PL Bonus Units MF                 80             5   \n",
       "6         PL Bonus Units SF                242            14   \n",
       "7     PL Bonus Units Infill               3746             4   \n",
       "8         WA Bonus Units MF                 22            12   \n",
       "9         WA Bonus Units SF                 52            52   \n",
       "10    WA Bonus Units Infill               4227             4   \n",
       "\n",
       "    Total_Forecasted_Units  Total_Remaining_Units  \n",
       "0                       24                    0.0  \n",
       "1                       34                    0.0  \n",
       "2                       10                    0.0  \n",
       "3                       23                    0.0  \n",
       "4                       10                    0.0  \n",
       "5                       10                    0.0  \n",
       "6                       14                    0.0  \n",
       "7                        4                    0.0  \n",
       "8                       31                   11.0  \n",
       "9                       52                    8.0  \n",
       "10                      18                    0.0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### ------------------------------------------------------UNIT ASSIGNMENTS BY POOL------------------------------------------------------ ####\n",
    "\n",
    "##-----------------------------------------------------------Bonus Unit Assignments-----------------------------------------------------------##\n",
    "## CSLT Bonus Unit Assignments ##\n",
    "# Assign Bonus Units to Multifamily zoned parcels within the Bonus Unit Boundary\n",
    "target_sum             = get_target_sum(dfPool, 'CSLT', 'Bonus Unit', 'MF')\n",
    "CSLT_Bonus_condition   = \"(df['JURISDICTION'] == 'CSLT') & (df['WITHIN_BONUSUNIT_BNDY'] == 'Yes')\" + \" & \" + trpa_boundary_criteria + \" & \" + vacant_buildable_criteria + \" & \" + sf_mf_criteria\n",
    "sdfParcels, df_summary = forecast_residential_units(sdfParcels, CSLT_Bonus_condition, target_sum, 'CSLT Bonus Units MF')\n",
    "df_built_parcels = df_summary\n",
    "# Assign Bonus Units to Single Family only zoned parcels within the Bonus Unit Boundary\n",
    "target_sum             = get_target_sum(dfPool, 'CSLT', 'Bonus Unit', 'SF')\n",
    "CSLT_Bonus_condition   = \"(df['JURISDICTION'] == 'CSLT') & (df['WITHIN_BONUSUNIT_BNDY'] == 'Yes')\" + \" & \" + trpa_boundary_criteria + \" & \" + vacant_buildable_criteria + \" & \" + sf_only_criteria\n",
    "sdfParcels, df_summary = forecast_residential_units(sdfParcels, CSLT_Bonus_condition, target_sum, 'CSLT Bonus Units SF')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "# Assign Bonus Units to Developable Infill parcels within the Bonus Unit Boundary\n",
    "target_sum             = get_target_sum(dfPool, 'CSLT', 'Bonus Unit', 'Infill')\n",
    "CSLT_Bonus_condition   = \"(df['JURISDICTION'] == 'CSLT') & (df['WITHIN_BONUSUNIT_BNDY'] == 'Yes')\" + \" & \" + trpa_boundary_criteria + \" & \" + sf_mf_criteria\n",
    "sdfParcels, df_summary = forecast_residential_units_infill(sdfParcels, CSLT_Bonus_condition, target_sum, 'CSLT Bonus Units Infill')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "## Douglas Bonus Unit Assignments ##\n",
    "# Assign Bonus Units to Multifamily zoned parcels within the Bonus Unit Boundary\n",
    "target_sum             = get_target_sum(dfPool, 'DG', 'Bonus Unit', 'MF')\n",
    "DG_Bonus_condition     = \"(df['JURISDICTION'] == 'DG') & (df['WITHIN_BONUSUNIT_BNDY'] == 'Yes')\" + \" & \" + trpa_boundary_criteria + \" & \" + vacant_buildable_criteria + \" & \" + sf_mf_criteria\n",
    "sdfParcels, df_summary = forecast_residential_units(sdfParcels, DG_Bonus_condition, target_sum, 'DG Bonus Units MF')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "# Assign Bonus Units to Single Family only zoned parcels within the Bonus Unit Boundary\n",
    "target_sum             = get_target_sum(dfPool, 'DG', 'Bonus Unit', 'SF')\n",
    "DG_Bonus_condition     = \"(df['JURISDICTION'] == 'DG') & (df['WITHIN_BONUSUNIT_BNDY'] == 'Yes')\" + \" & \" + trpa_boundary_criteria + \" & \" + vacant_buildable_criteria + \" & \" + sf_only_criteria\n",
    "sdfParcels, df_summary = forecast_residential_units(sdfParcels, DG_Bonus_condition, target_sum, 'DG Bonus Units SF')\n",
    "# Assign Bonus Units to Developable Infill parcels within the Bonus Unit Boundary\n",
    "target_sum             = get_target_sum(dfPool, 'DG', 'Bonus Unit', 'Infill')\n",
    "DG_Bonus_condition     = \"(df['JURISDICTION'] == 'DG') & (df['WITHIN_BONUSUNIT_BNDY'] == 'Yes')\" + \" & \" + trpa_boundary_criteria +  \" & \" + sf_mf_criteria\n",
    "sdfParcels, df_summary = forecast_residential_units_infill(sdfParcels, DG_Bonus_condition, target_sum, 'DG Bonus Units Infill')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "\n",
    "## Placer Bonus Unit Assignments ##\n",
    "# Assign Bonus Units to Multifamily zoned parcels within the Bonus Unit Boundary\n",
    "target_sum             = get_target_sum(dfPool, 'PL', 'Bonus Unit', 'MF')\n",
    "PL_Bonus_condition     = \"(df['JURISDICTION'] == 'PL') & (df['WITHIN_BONUSUNIT_BNDY'] == 'Yes')\" + \" & \" + trpa_boundary_criteria + \" & \" + placer_vacant_buildable_criteria + \" & \" + sf_mf_criteria\n",
    "sdfParcels, df_summary = forecast_residential_units(sdfParcels, PL_Bonus_condition, target_sum, 'PL Bonus Units MF')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "# Assign Bonus Units to Single Family only zoned parcels within the Bonus Unit Boundary\n",
    "target_sum             = get_target_sum(dfPool, 'PL', 'Bonus Unit', 'SF')\n",
    "PL_Bonus_condition     = \"(df['JURISDICTION'] == 'PL') & (df['WITHIN_BONUSUNIT_BNDY'] == 'Yes')\" + \" & \" + trpa_boundary_criteria + \" & \" + placer_vacant_buildable_criteria + \" & \" + sf_only_criteria\n",
    "sdfParcels, df_summary = forecast_residential_units(sdfParcels, PL_Bonus_condition, target_sum, 'PL Bonus Units SF')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "# Assign Bonus Units to Developable Infill parcels within the Bonus Unit Boundary\n",
    "target_sum             = get_target_sum(dfPool, 'PL', 'Bonus Unit', 'Infill')\n",
    "PL_Bonus_condition     = \"(df['JURISDICTION'] == 'PL') & (df['WITHIN_BONUSUNIT_BNDY'] == 'Yes')\" + \" & \" + trpa_boundary_criteria +  \" & \" + sf_mf_criteria\n",
    "sdfParcels, df_summary = forecast_residential_units(sdfParcels, PL_Bonus_condition, target_sum, 'PL Bonus Units Infill')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "\n",
    "## Washoe Bonus Unit Assignments ##\n",
    "# Assign Bonus Units to Multifamily zoned parcels within the Bonus Unit Boundary\n",
    "target_sum             = get_target_sum(dfPool, 'WA', 'Bonus Unit', 'MF')\n",
    "WA_Bonus_condition     = \"(df['JURISDICTION'] == 'WA') & (df['WITHIN_BONUSUNIT_BNDY'] == 'Yes')\" + \" & \" + trpa_boundary_criteria + \" & \" + vacant_buildable_criteria + \" & \" + sf_mf_criteria\n",
    "sdfParcels, df_summary = forecast_residential_units(sdfParcels, WA_Bonus_condition, target_sum, 'WA Bonus Units MF')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "# Assign Bonus Units to Single Family only zoned parcels within the Bonus Unit Boundary\n",
    "target_sum             = get_target_sum(dfPool, 'WA', 'Bonus Unit', 'SF')\n",
    "WA_Bonus_condition     = \"(df['JURISDICTION'] == 'WA') & (df['WITHIN_BONUSUNIT_BNDY'] == 'Yes')\" + \" & \" + trpa_boundary_criteria + \" & \" + vacant_buildable_criteria + \" & \" + sf_only_criteria\n",
    "sdfParcels, df_summary = forecast_residential_units(sdfParcels, WA_Bonus_condition, target_sum, 'WA Bonus Units SF')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "# Assign Bonus Units to Developable Infill parcels within the Bonus Unit Boundary\n",
    "target_sum             = get_target_sum(dfPool, 'WA', 'Bonus Unit', 'Infill')\n",
    "WA_Bonus_condition     = \"(df['JURISDICTION'] == 'WA') & (df['WITHIN_BONUSUNIT_BNDY'] == 'Yes')\" + \" & \" + trpa_boundary_criteria + \" & \" + sf_mf_criteria\n",
    "sdfParcels, df_summary = forecast_residential_units_infill(sdfParcels, WA_Bonus_condition, target_sum, 'WA Bonus Units Infill')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "\n",
    "df_built_parcels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Adjust the Pools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust pools after Bonus Unit Assignments\n",
    "dfPool_Deductions, dfPool = adjust_pools(sdfParcels, dfPool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Future_Units: 4385\n",
      "Future_Units_Adjusted: 3108.0\n",
      "Unit_Change: 1277.0\n"
     ]
    }
   ],
   "source": [
    "# sum of forecasted units, forecasted units adjusted, and unit change\n",
    "for i in ['Future_Units', 'Future_Units_Adjusted', 'Unit_Change']:\n",
    "    print(f\"{i}: {dfPool[i].sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Assign Units using General Unit Pools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ----------------------------------------------------General Unit Assignments---------------------------------------------------- ##\n",
    "## CSTL General Unit Assignments ##\n",
    "# Assign General Jurisdiction Units to Multifamily zoned parcels\n",
    "target_sum             = get_target_sum(dfPool, 'CSLT', 'General', 'MF')\n",
    "CSLT_MF_condition     = \"(df['JURISDICTION'] == 'CSLT') & \" + trpa_boundary_criteria + \" & \" + vacant_buildable_criteria + \" & \" + sf_mf_criteria\n",
    "sdfParcels, df_summary = forecast_residential_units(sdfParcels, CSLT_MF_condition, target_sum, 'CSLT General Units MF')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "# Assign General Jurisdiction Units to Single Family only zoned parcels\n",
    "target_sum             = get_target_sum(dfPool, 'CSLT', 'General', 'SF')\n",
    "CSLT_SF_condition     = \"(df['JURISDICTION'] == 'CSLT') & \" + trpa_boundary_criteria + \" & \" + vacant_buildable_criteria + \" & \" + sf_only_criteria\n",
    "sdfParcels, df_summary = forecast_residential_units(sdfParcels, CSLT_SF_condition, target_sum, 'CSLT General Units SF')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "# Assign General Jurisdiction Units to Developable Infill parcels\n",
    "target_sum             = get_target_sum(dfPool, 'CSLT', 'General', 'Infill')\n",
    "CSLT_Infill_condition = \"(df['JURISDICTION'] == 'CSLT') & \" + trpa_boundary_criteria + \" & \" + vacant_buildable_criteria + \" & \" + sf_mf_criteria\n",
    "sdfParcels, df_summary = forecast_residential_units_infill(sdfParcels, CSLT_Infill_condition, target_sum, 'CSLT General Units Infill')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "\n",
    "## El Dorado General Unit Assignments ##\n",
    "# Assign General Jurisdiction Units to Multifamily zoned parcels\n",
    "target_sum             = get_target_sum(dfPool, 'EL', 'General', 'MF')\n",
    "EL_MF_condition        = \"(df['JURISDICTION'] == 'EL') & \" + trpa_boundary_criteria + \" & \" + vacant_buildable_criteria + \" & \" + sf_mf_criteria\n",
    "sdfParcels, df_summary = forecast_residential_units(sdfParcels, EL_MF_condition, target_sum, 'EL General Units MF')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "# Assign General Jurisdiction Units to Single Family only zoned parcels\n",
    "target_sum             = get_target_sum(dfPool, 'EL', 'General', 'SF')\n",
    "EL_SF_condition        = \"(df['JURISDICTION'] == 'EL') & \" + trpa_boundary_criteria + \" & \" + vacant_buildable_criteria + \" & \" + sf_only_criteria\n",
    "sdfParcels, df_summary = forecast_residential_units(sdfParcels, EL_SF_condition, target_sum, 'EL General Units SF')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "# Assign General Jurisdiction Units to Developable Infill parcels\n",
    "target_sum             = get_target_sum(dfPool, 'EL', 'General', 'Infill')\n",
    "EL_Infill_condition    = \"(df['JURISDICTION'] == 'EL') & \" + trpa_boundary_criteria + \" & \" + vacant_buildable_criteria + \" & \" + sf_mf_criteria\n",
    "sdfParcels, df_summary = forecast_residential_units_infill(sdfParcels, EL_Infill_condition, target_sum, 'EL General Units Infill')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "\n",
    "# Placer General Unit Assignments\n",
    "# Assign General Jurisdiction Units to Multifamily zoned parcels\n",
    "target_sum             = get_target_sum(dfPool, 'PL', 'General', 'MF')\n",
    "PL_MF_condition        = \"(df['JURISDICTION'] == 'PL') & \" + trpa_boundary_criteria + \" & \" + vacant_buildable_criteria + \" & \" + sf_mf_criteria\n",
    "sdfParcels, df_summary = forecast_residential_units(sdfParcels, PL_MF_condition, target_sum, 'PL General Units MF')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "# Assign General Jurisdiction Units to Single Family only zoned parcels\n",
    "target_sum             = get_target_sum(dfPool, 'PL', 'General', 'SF')\n",
    "PL_SF_condition        = \"(df['JURISDICTION'] == 'PL') & \" + trpa_boundary_criteria + \" & \" + placer_vacant_buildable_criteria + \" & \" + sf_only_criteria\n",
    "sdfParcels, df_summary = forecast_residential_units(sdfParcels, PL_SF_condition, target_sum, 'PL General Units SF')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "# Assign General Jurisdiction Units to Developable Infill parcels\n",
    "target_sum             = get_target_sum(dfPool, 'PL', 'General', 'Infill')\n",
    "PL_Infill_condition    = \"(df['JURISDICTION'] == 'PL') & \" + trpa_boundary_criteria + \" & \" + placer_vacant_buildable_criteria + \" & \" + sf_mf_criteria\n",
    "sdfParcels, df_summary = forecast_residential_units_infill(sdfParcels, PL_Infill_condition, target_sum, 'PL General Units Infill')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "\n",
    "# Douglas General Unit Assignments\n",
    "# Assign General Jurisdiction Units to Multifamily zoned parcels\n",
    "target_sum             = get_target_sum(dfPool, 'DG', 'General', 'MF')\n",
    "DG_MF_condition        = \"(df['JURISDICTION'] == 'DG') & \" + trpa_boundary_criteria + \" & \" + vacant_buildable_criteria + \" & \" + sf_mf_criteria\n",
    "sdfParcels, df_summary = forecast_residential_units(sdfParcels, DG_MF_condition, target_sum, 'DG General Units MF')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "# Assign General Jurisdiction Units to Single Family only zoned parcels\n",
    "target_sum             = get_target_sum(dfPool, 'DG', 'General', 'SF')\n",
    "DG_SF_condition        = \"(df['JURISDICTION'] == 'DG') & \" + trpa_boundary_criteria + \" & \" + vacant_buildable_criteria + \" & \" + sf_only_criteria\n",
    "sdfParcels, df_summary = forecast_residential_units(sdfParcels, DG_SF_condition, target_sum, 'DG General Units SF')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "# Assign General Jurisdiction Units to Developable Infill parcels\n",
    "target_sum             = get_target_sum(dfPool, 'DG', 'General', 'Infill')\n",
    "DG_Infill_condition    = \"(df['JURISDICTION'] == 'DG') & \" + trpa_boundary_criteria + \" & \" + vacant_buildable_criteria + \" & \" + sf_mf_criteria\n",
    "sdfParcels, df_summary = forecast_residential_units_infill(sdfParcels, DG_Infill_condition, target_sum, 'DG General Units Infill')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "\n",
    "# Washoe General Unit Assignments\n",
    "# Assign General Jurisdiction Units to Multifamily zoned parcels \n",
    "target_sum             = get_target_sum(dfPool, 'WA', 'General', 'MF')\n",
    "WA_MF_condition        = \"(df['JURISDICTION'] == 'WA') & \" + trpa_boundary_criteria + \" & \" + vacant_buildable_criteria + \" & \" + sf_mf_criteria\n",
    "sdfParcels, df_summary = forecast_residential_units(sdfParcels, WA_MF_condition, target_sum, 'WA General Units MF')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "# Assign General Jurisdiction Units to Single Family only zoned parcels\n",
    "target_sum             = get_target_sum(dfPool, 'WA', 'General', 'SF')\n",
    "WA_SF_condition        = \"(df['JURISDICTION'] == 'WA') & \" + trpa_boundary_criteria + \" & \" + vacant_buildable_criteria + \" & \" + sf_only_criteria\n",
    "sdfParcels, df_summary = forecast_residential_units(sdfParcels, WA_SF_condition, target_sum, 'WA General Units SF')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "# Assign General Jurisdiction Units to Developable Infill parcels\n",
    "target_sum             = get_target_sum(dfPool, 'WA', 'General', 'Infill')\n",
    "WA_Infill_condition    = \"(df['JURISDICTION'] == 'WA') & \" + trpa_boundary_criteria + \" & \" + sf_mf_criteria\n",
    "sdfParcels, df_summary = forecast_residential_units_infill(sdfParcels, WA_Infill_condition, target_sum, 'WA General Units Infill')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Adjust the Pools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'FORECASTED_RESIDENTIAL_UNITS'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3651\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3652\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3653\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\Lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\Lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'FORECASTED_RESIDENTIAL_UNITS'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_42016\\1604962498.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# adjust pools after Bonus Unit Assignments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdfPool_Deductions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdfPool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madjust_pools\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msdfParcels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdfPool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_42016\\3169864557.py\u001b[0m in \u001b[0;36madjust_pools\u001b[1;34m(df, dfPool)\u001b[0m\n\u001b[0;32m    193\u001b[0m     \u001b[0mdfPool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdfPool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdfPool_Deductions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Unit_Pool'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'left'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m     \u001b[1;31m# fill NaN with 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 195\u001b[1;33m     \u001b[0mdfPool\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'FORECASTED_RESIDENTIAL_UNITS'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdfPool\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'FORECASTED_RESIDENTIAL_UNITS'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m     \u001b[1;31m# adjust the forecasted units\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[0mdfPool\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Future_Units_Adjusted'\u001b[0m\u001b[1;33m]\u001b[0m    \u001b[1;33m=\u001b[0m \u001b[0mdfPool\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Future_Units_Adjusted'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mdfPool\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'FORECASTED_RESIDENTIAL_UNITS'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3761\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3762\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3763\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3653\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3654\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3655\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3656\u001b[0m             \u001b[1;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'FORECASTED_RESIDENTIAL_UNITS'"
     ]
    }
   ],
   "source": [
    "# adjust pools after Bonus Unit Assignments\n",
    "dfPool_Deductions, dfPool = adjust_pools(sdfParcels, dfPool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Future_Units: 4385\n",
      "Future_Units_Adjusted: 3108.0\n",
      "Unit_Change: 1277.0\n"
     ]
    }
   ],
   "source": [
    "# sum of forecasted units, forecasted units adjusted, and unit change\n",
    "for i in ['Future_Units', 'Future_Units_Adjusted', 'Unit_Change']:\n",
    "    print(f\"{i}: {dfPool[i].sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Forecast TRPA Pools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ------------------------------------------------------UNIT ASSIGNMENTS BY POOL------------------------------------------------------ ####\n",
    "dfPool = dfPool.copy()\n",
    "##-----------------------------------------------------------Bonus Unit Assignments-----------------------------------------------------------##\n",
    "## TRPA Bonus Unit Assignments ##\n",
    "# Assign Bonus Units to Multifamily zoned parcels within the Bonus Unit Boundary\n",
    "target_sum             = get_target_sum(dfPool, 'TRPA', 'Bonus Unit', 'MF')\n",
    "TRPA_Bonus_condition   = \"(df['WITHIN_BONUSUNIT_BNDY'] == 'Yes')\" + \" & \" + trpa_boundary_criteria + \" & \" + vacant_buildable_criteria + \" & \" + sf_mf_criteria\n",
    "sdfParcels, df_summary = forecast_residential_units(sdfParcels, TRPA_Bonus_condition, target_sum, 'TRPA Bonus Units MF')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "# Assign Bonus Units to Single Family only zoned parcels within the Bonus Unit Boundary\n",
    "target_sum             = get_target_sum(dfPool, 'TRPA', 'Bonus Unit', 'SF')\n",
    "TRPA_Bonus_condition   = \"(df['WITHIN_BONUSUNIT_BNDY'] == 'Yes')\" + \" & \" + trpa_boundary_criteria + \" & \" + vacant_buildable_criteria + \" & \" + sf_only_criteria\n",
    "sdfParcels, df_summary = forecast_residential_units(sdfParcels, TRPA_Bonus_condition, target_sum, 'TRPA Bonus Units SF')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "# Assign Bonus Units to Developable Infill parcels within the Bonus Unit Boundary\n",
    "target_sum             = get_target_sum(dfPool, 'TRPA', 'Bonus Unit', 'Infill')\n",
    "TRPA_Bonus_condition   = \"(df['WITHIN_BONUSUNIT_BNDY'] == 'Yes')\" + \" & \" + trpa_boundary_criteria + \" & \" + sf_mf_criteria\n",
    "sdfParcels, df_summary = forecast_residential_units_infill(sdfParcels, TRPA_Bonus_condition, target_sum, 'TRPA Bonus Units Infill')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "\n",
    "## TRPA General Unit Assignments ##\n",
    "# Assign General Jurisdiction Units to Multifamily zoned parcels\n",
    "target_sum             = get_target_sum(dfPool, 'TRPA', 'General', 'MF')\n",
    "TRPA_MF_condition      = trpa_boundary_criteria + \" & \" + vacant_buildable_criteria + \" & \" + sf_mf_criteria\n",
    "sdfParcels, df_summary = forecast_residential_units(sdfParcels, TRPA_MF_condition, target_sum, 'TRPA General Units MF')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "# Assign General Jurisdiction Units to Single Family only zoned parcels\n",
    "target_sum             = get_target_sum(dfPool, 'TRPA', 'General', 'SF')\n",
    "TRPA_SF_condition     = trpa_boundary_criteria + \" & \" + vacant_buildable_criteria + \" & \" + sf_only_criteria\n",
    "sdfParcels, df_summary = forecast_residential_units(sdfParcels, TRPA_SF_condition, target_sum, 'TRPA General Units SF')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "# Assign General Jurisdiction Units to Developable Infill parcels\n",
    "target_sum             = get_target_sum(dfPool, 'TRPA', 'General', 'Infill')\n",
    "TRPA_Infill_condition = trpa_boundary_criteria + \" & \" + vacant_buildable_criteria + \" & \" + sf_mf_criteria\n",
    "sdfParcels, df_summary = forecast_residential_units_infill(sdfParcels, TRPA_Infill_condition, target_sum, 'TRPA General Units Infill')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "\n",
    "# assign ADUs to existing residential parcels residential units=1 and ADU_ALLOWED = Yes\n",
    "target_sum = get_target_sum(dfPool, 'TRPA', 'General', 'ADU')\n",
    "TRPA_ADU_condition = trpa_boundary_criteria + \" & \" + adu_criteria\n",
    "sdfParcels, df_summary = forecast_residential_units(sdfParcels, TRPA_ADU_condition, target_sum, 'TRPA ADU Units')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "\n",
    "# assign the rest of units to Town Center infill\n",
    "target_sum = get_target_sum(dfPool, 'TRPA', 'General', 'Infill')\n",
    "TRPA_Infill_condition = trpa_boundary_criteria + \" & \" + towncenter_condition + \" & \"+ vacant_buildable_criteria + \" & \" + sf_mf_criteria\n",
    "sdfParcels, df_summary = forecast_residential_units_infill(sdfParcels, TRPA_Infill_condition, target_sum, 'TRPA Town Center Infill Units')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n",
    "\n",
    "# assign the remainder to within a quarter mile of town center\n",
    "target_sum = get_target_sum(dfPool, 'TRPA', 'General', 'Infill')\n",
    "TRPA_Infill_condition = trpa_boundary_criteria + \" & \" + tc_quarter_condition + \" & \"+ vacant_buildable_criteria + \" & \" + sf_mf_criteria\n",
    "sdfParcels, df_summary = forecast_residential_units_infill(sdfParcels, TRPA_Infill_condition, target_sum, 'TRPA Quarter Mile Infill Units')\n",
    "df_built_parcels = pd.concat([df_built_parcels, df_summary], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Adjust the Pools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust pools after Bonus Unit Assignments\n",
    "dfPool_Deductions, dfPool = adjust_pools(sdfParcels, dfPool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum of forecasted units, forecasted units adjusted, and unit change\n",
    "for i in ['Future_Units', 'Future_Units_Adjusted', 'Unit_Change']:\n",
    "    print(f\"{i}: {dfPool[i].sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Assign the Remainders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign Units to SF/MF and MF only parcels, 35% of all pools to MF only parcels\n",
    "# Check total units available\n",
    "# Assign Units to SF only parcels, 50% of all pools to SF only parcels\n",
    "# Assign Units to underbuilt MF parcels within the Bonus Unit Boundary\n",
    "# Assign Units to parcels within a Town Center\n",
    "# Assign Units to parcels within 1/4 mile of a Town Center\n",
    "## TRPA ADU Unit Assignments ##\n",
    "# Assign remaining Units to parcels eligible for ADU constuction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Assign Forecast Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Development_Year\n",
       "2035    2005.0\n",
       "2050    2274.0\n",
       "Name: FORECASTED_RESIDENTIAL_UNITS, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Assigning Development Year to Parcels ##\n",
    "# Get total development by 2035\n",
    "TotalDevelopment = dfResZoned.Future_Units.sum()\n",
    "Development_2035 = (TotalDevelopment*.46).astype(int)\n",
    "sdfParcels['Development_Year']=None\n",
    "#Assining all development that's currently in the works as being cone by 2035\n",
    "sdfParcels.loc[sdfParcels['FORECAST_REASON'] == 'Assigned', 'Development_Year'] = 2035\n",
    "RemainingDevelopment_2035 = Development_2035 - sdfParcels.loc[sdfParcels['FORECAST_REASON'] == 'Assigned', 'FORECASTED_RESIDENTIAL_UNITS'].sum()\n",
    "\n",
    "Development_2035_Condition = sdfParcels['FORECASTED_RESIDENTIAL_UNITS'].where(sdfParcels['FORECAST_REASON'] != 'Assigned').cumsum()\n",
    "sdfParcels.loc[Development_2035_Condition < RemainingDevelopment_2035, 'Development_Year'] = 2035\n",
    "sdfParcels.loc[(sdfParcels['FORECAST_REASON']!= '') & (sdfParcels['Development_Year'].isnull()), 'Development_Year'] = 2050\n",
    "development_year = sdfParcels.groupby('Development_Year')['FORECASTED_RESIDENTIAL_UNITS'].sum()\n",
    "development_year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assign Occupancy Rate to all forecasted residential parcels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdfParcels['FORECASTED_OCCUPANCY_RATE'] = 0\n",
    "# map lookup known project occupancy rates to parcels\n",
    "sdfParcels['FORECASETED_OCCUPANCY_RATE'] = sdfParcels['APN'].map(dict(zip(dfResAssigned.APN, dfResAssigned['Occupancy_Rate'])))\n",
    "sdfParcels.FORECAST_REASON.value_counts()\n",
    "\n",
    "# if FORECAST_REASON has the word 'Bonus' in it set occupancy rate to 100%\n",
    "sdfParcels.loc[sdfParcels['FORECAST_REASON'].fillna('').str.contains('Bonus'), 'FORECASTED_OCCUPANCY_RATE'] = 1\n",
    "# if FORECAST_REASON has the word 'CTC' in it set occupancy rate to 100%\n",
    "sdfParcels.loc[sdfParcels['FORECAST_REASON'].fillna('').str.contains('CTC'), 'FORECASTED_OCCUPANCY_RATE'] = 1\n",
    "# if FORECAST_REASON has the word 'General' and housing zoning is SF_only in it set occupancy rate to 35\n",
    "sdfParcels.loc[(sdfParcels['FORECAST_REASON'].fillna('').str.contains('General')) & (sdfParcels['HOUSING_ZONING'] == 'SF_only'), 'FORECASTED_OCCUPANCY_RATE'] = 0.35"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'FORECASTED_RESIDENTIAL_UNITS'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3651\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3652\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3653\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\Lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\Lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'FORECASTED_RESIDENTIAL_UNITS'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_42016\\1324308765.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mbuilt_units\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Unit_Pool'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuilt_units\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mForecast_Reason_lookup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Unit_Pool'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0munit_comparison\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuilt_units\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdfResZoned\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'left'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Jurisdiction'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Unit_Pool'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0munit_comparison\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Difference'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munit_comparison\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Future_Units_Adjusted'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0munit_comparison\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'FORECASTED_RESIDENTIAL_UNITS'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[0munit_comparison\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'unit_comparison.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3761\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3762\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3763\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3653\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3654\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3655\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3656\u001b[0m             \u001b[1;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'FORECASTED_RESIDENTIAL_UNITS'"
     ]
    }
   ],
   "source": [
    "built_units = sdfParcels.groupby('FORECAST_REASON').agg({'FORECASTED_RESIDENTIAL_UNITS':'sum'})\n",
    "dfResZoned = dfPool.copy()\n",
    "# Create a dictionary to map the forecast reason to the Jurisdiction and Unit Pool\n",
    "Forecast_Reason_lookup = {'CSLT Bonus Units Built':{'Jurisdiction':'CSLT', 'Unit_Pool':'Bonus Unit'},\n",
    "                          'CSLT General Units Built':{'Jurisdiction':'CSLT', 'Unit_Pool':'General'},\n",
    "                          'EL General Units Built':{'Jurisdiction':'EL', 'Unit_Pool':'General'},\n",
    "                          'PL Bonus Units Built':{'Jurisdiction':'PL', 'Unit_Pool':'Bonus Unit'},\n",
    "                          'PL General Units Built':{'Jurisdiction':'PL', 'Unit_Pool':'General'},\n",
    "                          'WA Bonus Units Built':{'Jurisdiction':'WA', 'Unit_Pool':'Bonus Unit'},\n",
    "                          'WA General Units Built':{'Jurisdiction':'WA', 'Unit_Pool':'General'},\n",
    "                          'DG Bonus Units Built':{'Jurisdiction':'DG', 'Unit_Pool':'Bonus Unit'},\n",
    "                          'DG General Units Built':{'Jurisdiction':'DG', 'Unit_Pool':'General'},\n",
    "                          'TRPA Bonus Units Built':{'Jurisdiction':'TRPA', 'Unit_Pool':'Bonus Unit'},\n",
    "                          'TRPA General Units Built':{'Jurisdiction':'TRPA', 'Unit_Pool':'General'},\n",
    "                          'ADU Units Built':{'Jurisdiction':'TRPA', 'Unit_Pool':'ADU'}}\n",
    "# Map 'Jurisdiction' and 'Unit_Pool' separately from the dictionary\n",
    "built_units['Jurisdiction'] = built_units.index.map(lambda x: Forecast_Reason_lookup.get(x, {}).get('Jurisdiction'))\n",
    "built_units['Unit_Pool'] = built_units.index.map(lambda x: Forecast_Reason_lookup.get(x, {}).get('Unit_Pool'))\n",
    "unit_comparison = built_units.merge(dfResZoned, how='left', on=['Jurisdiction', 'Unit_Pool'])\n",
    "unit_comparison['Difference'] = unit_comparison['Future_Units_Adjusted'] - unit_comparison['FORECASTED_RESIDENTIAL_UNITS']\n",
    "unit_comparison.to_csv('unit_comparison.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LOCATION_TO_TOWNCENTER                      FORECAST_REASON          \n",
       "Further than Quarter Mile from Town Center  Assigned                     341.0\n",
       "                                            CSLT Bonus Units MF            1.0\n",
       "                                            CSLT Bonus Units SF           16.0\n",
       "                                            CSLT General Units Infill     12.0\n",
       "                                            CSLT General Units MF         44.0\n",
       "                                            CSLT General Units SF        122.0\n",
       "                                            CTC Asset Lands               13.0\n",
       "                                            DG Bonus Units Infill          5.0\n",
       "                                            DG Bonus Units MF              1.0\n",
       "                                            DG Bonus Units SF              7.0\n",
       "                                            DG General Units SF           24.0\n",
       "                                            EL General Units MF            1.0\n",
       "                                            EL General Units SF          106.0\n",
       "                                            PL Bonus Units SF             10.0\n",
       "                                            PL General Units Infill       30.0\n",
       "                                            PL General Units MF           86.0\n",
       "                                            PL General Units SF          197.0\n",
       "                                            TRPA ADU Units               524.0\n",
       "                                            TRPA Bonus Units Infill        2.0\n",
       "                                            TRPA Bonus Units MF           35.0\n",
       "                                            TRPA Bonus Units SF          138.0\n",
       "                                            TRPA General Units MF         61.0\n",
       "                                            TRPA General Units SF        472.0\n",
       "                                            WA Bonus Units MF              2.0\n",
       "                                            WA Bonus Units SF             22.0\n",
       "                                            WA General Units Infill       66.0\n",
       "                                            WA General Units SF           55.0\n",
       "Within Quarter Mile of Town Center          Assigned                      54.0\n",
       "                                            CSLT Bonus Units MF            1.0\n",
       "                                            CSLT Bonus Units SF           13.0\n",
       "                                            CSLT General Units Infill     23.0\n",
       "                                            CSLT General Units MF         45.0\n",
       "                                            CSLT General Units SF         43.0\n",
       "                                            CTC Asset Lands                0.0\n",
       "                                            DG Bonus Units SF              3.0\n",
       "                                            EL General Units MF            5.0\n",
       "                                            EL General Units SF           14.0\n",
       "                                            PL Bonus Units MF              4.0\n",
       "                                            PL General Units Infill       13.0\n",
       "                                            PL General Units MF           39.0\n",
       "                                            PL General Units SF           18.0\n",
       "                                            TRPA ADU Units               271.0\n",
       "                                            TRPA Bonus Units Infill        4.0\n",
       "                                            TRPA Bonus Units MF           92.0\n",
       "                                            TRPA Bonus Units SF           71.0\n",
       "                                            TRPA General Units MF         65.0\n",
       "                                            TRPA General Units SF         40.0\n",
       "                                            WA Bonus Units MF              7.0\n",
       "                                            WA Bonus Units SF             30.0\n",
       "                                            WA General Units Infill      401.0\n",
       "Within Town Center                          Assigned                     623.0\n",
       "                                            CSLT General Units Infill     19.0\n",
       "                                            CSLT General Units MF         28.0\n",
       "                                            CTC Asset Lands               41.0\n",
       "                                            DG Bonus Units Infill         10.0\n",
       "                                            DG Bonus Units MF             22.0\n",
       "                                            DG General Units MF            3.0\n",
       "                                            EL General Units MF           28.0\n",
       "                                            PL Bonus Units MF              3.0\n",
       "                                            PL General Units Infill        5.0\n",
       "                                            PL General Units MF           25.0\n",
       "                                            TRPA ADU Units               229.0\n",
       "                                            TRPA Bonus Units Infill        8.0\n",
       "                                            TRPA Bonus Units MF           21.0\n",
       "                                            TRPA General Units MF         58.0\n",
       "                                            WA Bonus Units MF             17.0\n",
       "                                            WA General Units Infill      397.0\n",
       "Name: FORECASTED_RESIDENTIAL_UNITS, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forecasted residential uints by location to twon center\n",
    "sdfParcels.groupby(['LOCATION_TO_TOWNCENTER','FORECAST_REASON'])['FORECASTED_RESIDENTIAL_UNITS'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize Existing and Forecasted Units by Jurisdiction and Unit Pool by TAZ\n",
    "dfTAZ = sdfParcels.groupby('TAZ')[['FORECASTED_RESIDENTIAL_UNITS', 'Residential_Units']].sum().reset_index()\n",
    "dfTAZ.to_csv(data_dir/'TAZ_Units.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Development_Year</th>\n",
       "      <th>FORECASTED_RESIDENTIAL_UNITS</th>\n",
       "      <th>Residential_Units</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2035</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2050</td>\n",
       "      <td>2274.0</td>\n",
       "      <td>48562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Development_Year  FORECASTED_RESIDENTIAL_UNITS  Residential_Units\n",
       "0              2035                        2005.0                862\n",
       "1              2050                        2274.0              48562"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gropu by TAZ and sum forecasted residential units and residential units\n",
    "# Forecast year total residential units by TAZ\n",
    "sdfParcels.groupby('TAZ')[['FORECASTED_RESIDENTIAL_UNITS', 'Residential_Units']].sum().reset_index()\n",
    "# total units with forecast year 2035 and 2050\n",
    "sdfParcels.groupby('Development_Year')[['FORECASTED_RESIDENTIAL_UNITS', 'Residential_Units']].sum().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tourist Accommodation Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lookup lists\n",
    "tau_assigned_lookup = \"Lookup_Lists/forecast_tourist_assigned_units.csv\"\n",
    "# get assigned units lookup as data frames\n",
    "dfTouristAssigned = pd.read_csv(tau_assigned_lookup)\n",
    "# assign tourist units to parcels\n",
    "sdfParcels['FORECASTED_TAU_UNITS'] = 0\n",
    "# set tourist units to assigned total\n",
    "sdfParcels['FORECASTED_TAU_UNITS'] = sdfParcels.APN.map(dict(zip(dfTouristAssigned.APN, dfTouristAssigned['Unit_Pool'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commercial Floor Area Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lookup lists\n",
    "cfa_assigned_lookup = \"Lookup_Lists/forecast_commercial_assigned_units.csv\"\n",
    "# get zoned units lookups as data frames\n",
    "dfCommercialAssigned = pd.read_csv(cfa_assigned_lookup)\n",
    "# set commercial floor area to assigned total\n",
    "sdfParcels['FORECASTED_COMMERCIAL_FLOOR_AREA'] = 0\n",
    "sdfParcels['FORECASTED_COMMERCIAL_FLOOR_AREA'] = sdfParcels.APN.map(dict(zip(dfCommercialAssigned.APN, dfCommercialAssigned['NEW_CFA'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\mbindl\\\\Desktop\\\\Workspace.gdb\\\\Parcel_Forecast'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# export to pickle\n",
    "sdfParcels.to_pickle(parcel_pickle_part2)\n",
    "# to csv\n",
    "sdfParcels.to_csv(data_dir/'Parcels_Forecast.csv', index=False)\n",
    "# to feature class\n",
    "sdfParcels.spatial.to_featureclass(Path(gdb)/'Parcel_Forecast')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arcgispro-py3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
